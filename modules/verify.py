"""CYRBER VERIFY â€” fraud & scam verification for URLs, companies, and emails.

Aggregates signals from multiple OSINT sources (WHOIS, Google Safe Browsing,
VirusTotal, URLhaus, GreyNoise, Wayback Machine, KRS/CEIDG, Companies House,
MX records, disposable-email lists) and produces a risk score + AI verdict.
"""

import json
import logging
import os
import re
import socket
import time
from datetime import datetime, timezone
from urllib.parse import urlparse

import requests

log = logging.getLogger("cyrber.verify")

REQUEST_TIMEOUT = 15

# â”€â”€ ENV keys â”€â”€
GOOGLE_SAFE_BROWSING_KEY = os.getenv("GOOGLE_SAFE_BROWSING_KEY", "")
VIRUSTOTAL_KEY = os.getenv("VIRUSTOTAL_API_KEY", "") or os.getenv("VIRUSTOTAL_KEY", "")
COMPANIES_HOUSE_KEY = os.getenv("COMPANIES_HOUSE_KEY", "")
IPINFO_TOKEN = os.getenv("IPINFO_TOKEN", "")
ABUSEIPDB_API_KEY = os.getenv("ABUSEIPDB_API_KEY", "")
OTX_API_KEY = os.getenv("OTX_API_KEY", "")

# â”€â”€ Disposable email cache â”€â”€
_DISPOSABLE_DOMAINS: set[str] | None = None
_DISPOSABLE_URL = "https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/master/disposable_email_blocklist.conf"


def _load_disposable_domains() -> set[str]:
    """Load disposable email domain list (cached in memory)."""
    global _DISPOSABLE_DOMAINS
    if _DISPOSABLE_DOMAINS is not None:
        return _DISPOSABLE_DOMAINS
    try:
        resp = requests.get(_DISPOSABLE_URL, timeout=REQUEST_TIMEOUT)
        resp.raise_for_status()
        _DISPOSABLE_DOMAINS = {
            line.strip().lower()
            for line in resp.text.splitlines()
            if line.strip() and not line.startswith("#")
        }
        log.info(f"Loaded {len(_DISPOSABLE_DOMAINS)} disposable email domains")
    except Exception as exc:
        log.warning(f"Failed to load disposable domains: {exc}")
        _DISPOSABLE_DOMAINS = set()
    return _DISPOSABLE_DOMAINS


def _resolve_domain_ip(domain: str) -> str | None:
    """Resolve domain to IP address."""
    try:
        return socket.gethostbyname(domain)
    except socket.gaierror:
        return None


def _urlhaus_lookup(host: str) -> dict:
    """Wrapper around intelligence_sync.sync_urlhaus for testability.

    URLhaus /v1/host/ only supports IPs and domains â€” not email addresses.
    If host contains '@', extract the domain part first.
    """
    try:
        # Extract domain from email address if needed
        if "@" in host:
            host = host.split("@", 1)[1]
        from modules.intelligence_sync import sync_urlhaus
        return sync_urlhaus(host) or {"urls_count": 0, "blacklisted": False}
    except Exception:
        return {"urls_count": 0, "blacklisted": False}


def _greynoise_lookup(ip: str) -> dict:
    """Wrapper around intelligence_sync.sync_greynoise for testability."""
    try:
        from modules.intelligence_sync import sync_greynoise
        return sync_greynoise(ip) or {"classification": "unknown"}
    except Exception:
        return {"classification": "unknown"}


def _extract_domain(url_or_host: str) -> str:
    """Extract domain from URL or hostname."""
    if "://" in url_or_host:
        parsed = urlparse(url_or_host)
        return parsed.hostname or url_or_host
    return url_or_host.split("/")[0].split(":")[0]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  WHOIS LOOKUP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _whois_lookup(domain: str) -> dict:
    """Perform WHOIS lookup and return registration info."""
    try:
        import whois
        w = whois.whois(domain)
        creation = w.creation_date
        if isinstance(creation, list):
            creation = creation[0]

        expiration = w.expiration_date
        if isinstance(expiration, list):
            expiration = expiration[0]

        registrar = w.registrar or ""
        org = w.org or ""
        country = w.country or ""

        age_days = None
        if creation:
            if isinstance(creation, datetime):
                # Normalize to timezone-naive to avoid "can't subtract
                # offset-naive and offset-aware datetimes" error
                if hasattr(creation, 'tzinfo') and creation.tzinfo:
                    creation = creation.replace(tzinfo=None)
                age_days = (datetime.now() - creation).days
            creation = str(creation)

        if expiration and isinstance(expiration, datetime):
            expiration = str(expiration)

        return {
            "domain": domain,
            "registrar": registrar,
            "org": org,
            "country": country,
            "creation_date": creation,
            "expiration_date": str(expiration) if expiration else None,
            "age_days": age_days,
            "available": False,
        }
    except Exception as exc:
        log.warning(f"WHOIS lookup failed for {domain}: {exc}")
        return {"domain": domain, "error": str(exc), "age_days": None, "available": True}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  GOOGLE SAFE BROWSING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _google_safe_browsing(url: str) -> dict:
    """Check URL against Google Safe Browsing API."""
    if not GOOGLE_SAFE_BROWSING_KEY:
        return {"available": False, "reason": "no_api_key"}
    try:
        resp = requests.post(
            f"https://safebrowsing.googleapis.com/v4/threatMatches:find?key={GOOGLE_SAFE_BROWSING_KEY}",
            json={
                "client": {"clientId": "cyrber", "clientVersion": "0.3.0"},
                "threatInfo": {
                    "threatTypes": ["MALWARE", "SOCIAL_ENGINEERING", "UNWANTED_SOFTWARE", "POTENTIALLY_HARMFUL_APPLICATION"],
                    "platformTypes": ["ANY_PLATFORM"],
                    "threatEntryTypes": ["URL"],
                    "threatEntries": [{"url": url}],
                },
            },
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        data = resp.json()
        matches = data.get("matches", [])
        return {
            "available": True,
            "flagged": len(matches) > 0,
            "threats": [m.get("threatType", "") for m in matches],
        }
    except Exception as exc:
        log.warning(f"Google Safe Browsing failed: {exc}")
        return {"available": False, "error": str(exc)}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  VIRUSTOTAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _virustotal_url(url: str) -> dict:
    """Check URL against VirusTotal API."""
    if not VIRUSTOTAL_KEY:
        return {"available": False, "reason": "no_api_key"}
    try:
        import base64
        url_id = base64.urlsafe_b64encode(url.encode()).decode().rstrip("=")
        resp = requests.get(
            f"https://www.virustotal.com/api/v3/urls/{url_id}",
            headers={"x-apikey": VIRUSTOTAL_KEY},
            timeout=REQUEST_TIMEOUT,
        )
        if resp.status_code == 404:
            return {"available": True, "found": False, "positives": 0, "total": 0}
        resp.raise_for_status()
        data = resp.json().get("data", {}).get("attributes", {})
        stats = data.get("last_analysis_stats", {})
        positives = stats.get("malicious", 0) + stats.get("suspicious", 0)
        total = sum(stats.values()) if stats else 0
        return {
            "available": True,
            "found": True,
            "positives": positives,
            "total": total,
            "reputation": data.get("reputation", 0),
            "categories": data.get("categories", {}),
        }
    except Exception as exc:
        log.warning(f"VirusTotal URL check failed: {exc}")
        return {"available": False, "error": str(exc)}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  WAYBACK MACHINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _wayback_first(domain: str) -> dict:
    """Check first archive date via Wayback Machine CDX API."""
    try:
        resp = requests.get(
            f"https://web.archive.org/cdx/search/cdx?url={domain}&limit=1&output=json&fl=timestamp",
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        data = resp.json()
        if len(data) > 1:
            ts = data[1][0]  # first row after header
            first_date = datetime.strptime(ts[:8], "%Y%m%d")
            age_days = (datetime.now() - first_date).days
            return {"available": True, "first_archive": str(first_date.date()), "archive_age_days": age_days}
        return {"available": True, "first_archive": None, "archive_age_days": None}
    except Exception as exc:
        log.warning(f"Wayback Machine lookup failed for {domain}: {exc}")
        return {"available": False, "error": str(exc)}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MX RECORDS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _check_mx(domain: str) -> dict:
    """Check MX records for a domain."""
    try:
        import dns.resolver
        answers = dns.resolver.resolve(domain, "MX")
        records = [{"host": str(r.exchange).rstrip("."), "priority": r.preference} for r in answers]
        return {"has_mx": True, "records": records}
    except Exception:
        return {"has_mx": False, "records": []}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  RDAP (Registration Data Access Protocol)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _rdap_lookup(domain: str) -> dict:
    """Perform RDAP lookup for domain registration data."""
    try:
        resp = requests.get(f"https://rdap.org/domain/{domain}", timeout=REQUEST_TIMEOUT)
        if resp.status_code == 404:
            return {"available": False, "error": "not_found"}
        resp.raise_for_status()
        data = resp.json()

        registrar = ""
        registration = None
        expiry = None
        status = []

        # Extract registrar from entities
        for entity in data.get("entities", []):
            if "registrar" in entity.get("roles", []):
                vcard = entity.get("vcardArray", [None, []])[1] if entity.get("vcardArray") else []
                for item in vcard:
                    if isinstance(item, list) and len(item) >= 4 and item[0] == "fn":
                        registrar = item[3]

        # Extract dates from events
        for event in data.get("events", []):
            action = event.get("eventAction", "")
            date = event.get("eventDate", "")
            if action == "registration":
                registration = date
            elif action == "expiration":
                expiry = date

        status = data.get("status", [])

        return {
            "available": True,
            "registration": registration,
            "expiry": expiry,
            "registrar": registrar,
            "status": status,
        }
    except Exception as exc:
        log.warning(f"RDAP lookup failed for {domain}: {exc}")
        return {"available": False, "error": str(exc)}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CRT.SH (Certificate Transparency)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _crtsh_lookup(domain: str) -> dict:
    """Check oldest certificate via crt.sh."""
    try:
        resp = requests.get(
            f"https://crt.sh/?q={domain}&output=json&limit=1",
            timeout=REQUEST_TIMEOUT,
            headers={"Accept": "application/json"},
        )
        if resp.status_code == 404 or not resp.text.strip():
            return {"available": True, "cert_age_days": None}
        resp.raise_for_status()
        data = resp.json()
        if not data:
            return {"available": True, "cert_age_days": None}
        oldest = data[-1] if isinstance(data, list) else data
        not_before = oldest.get("not_before") or oldest.get("entry_timestamp", "")
        if not_before:
            cert_date = datetime.strptime(not_before[:10], "%Y-%m-%d")
            cert_age_days = (datetime.now() - cert_date).days
            return {"available": True, "cert_age_days": cert_age_days, "issuer": oldest.get("issuer_name", "")}
        return {"available": True, "cert_age_days": None}
    except Exception as exc:
        log.warning(f"crt.sh lookup failed for {domain}: {exc}")
        return {"available": False, "error": str(exc)}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  SPF / DMARC DNS check
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _check_spf_dmarc(domain: str) -> dict:
    """Check SPF and DMARC DNS TXT records."""
    result = {"has_spf": False, "has_dmarc": False}
    try:
        import dns.resolver
        try:
            answers = dns.resolver.resolve(domain, "TXT")
            for rdata in answers:
                txt = str(rdata).strip('"')
                if txt.startswith("v=spf1"):
                    result["has_spf"] = True
        except Exception:
            pass
        try:
            answers = dns.resolver.resolve(f"_dmarc.{domain}", "TXT")
            for rdata in answers:
                txt = str(rdata).strip('"')
                if txt.startswith("v=DMARC1"):
                    result["has_dmarc"] = True
        except Exception:
            pass
    except Exception as exc:
        log.warning(f"SPF/DMARC check failed for {domain}: {exc}")
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  IPINFO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _ipinfo_lookup(ip: str) -> dict:
    """Lookup IP info via ipinfo.io."""
    try:
        headers = {}
        url = f"https://ipinfo.io/{ip}/json"
        if IPINFO_TOKEN:
            headers["Authorization"] = f"Bearer {IPINFO_TOKEN}"
        resp = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        resp.raise_for_status()
        data = resp.json()
        return {
            "available": True,
            "org": data.get("org", ""),
            "country": data.get("country", ""),
            "city": data.get("city", ""),
            "hosting": data.get("hosting", False),
        }
    except Exception as exc:
        log.warning(f"IPinfo lookup failed for {ip}: {exc}")
        return {"available": False, "error": str(exc)}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ABUSEIPDB
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _abuseipdb_lookup(ip: str) -> dict:
    """Check IP against AbuseIPDB."""
    if not ABUSEIPDB_API_KEY:
        return {"available": False, "reason": "no_api_key"}
    try:
        resp = requests.get(
            "https://api.abuseipdb.com/api/v2/check",
            headers={"Key": ABUSEIPDB_API_KEY, "Accept": "application/json"},
            params={"ipAddress": ip, "maxAgeInDays": 90},
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        d = resp.json().get("data", {})
        return {
            "available": True,
            "abuseConfidenceScore": d.get("abuseConfidenceScore", 0),
            "totalReports": d.get("totalReports", 0),
            "isWhitelisted": d.get("isWhitelisted", False),
            "countryCode": d.get("countryCode", ""),
        }
    except Exception as exc:
        log.warning(f"AbuseIPDB lookup failed for {ip}: {exc}")
        return {"available": False, "error": str(exc)}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  OTX (AlienVault Open Threat Exchange)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _otx_lookup(domain: str) -> dict:
    """Check domain in AlienVault OTX."""
    try:
        headers = {"Accept": "application/json"}
        if OTX_API_KEY:
            headers["X-OTX-API-KEY"] = OTX_API_KEY
        resp = requests.get(
            f"https://otx.alienvault.com/api/v1/indicators/domain/{domain}/general",
            headers=headers,
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        data = resp.json()
        pulse_count = data.get("pulse_info", {}).get("count", 0)
        validation = data.get("validation", [])
        return {
            "available": True,
            "pulse_count": pulse_count,
            "validation": validation,
        }
    except Exception as exc:
        log.warning(f"OTX lookup failed for {domain}: {exc}")
        return {"available": False, "error": str(exc)}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  TRANCO (Top Sites Ranking)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _tranco_lookup(domain: str) -> dict:
    """Check domain ranking in Tranco top list."""
    try:
        resp = requests.get(
            f"https://tranco-list.eu/api/ranks/domain/{domain}",
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        data = resp.json()
        # Tranco returns ranks array
        ranks = data.get("ranks", [])
        rank = ranks[0].get("rank") if ranks else None
        return {"available": True, "rank": rank}
    except Exception as exc:
        log.warning(f"Tranco lookup failed for {domain}: {exc}")
        return {"available": False, "rank": None}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  COMPANY REGISTRIES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _krs_lookup(nip_or_name: str) -> dict:
    """Check Polish KRS registry."""
    # Detect if it's a NIP (10 digits) or name
    clean = re.sub(r"[\s-]", "", nip_or_name)
    if re.match(r"^\d{10}$", clean):
        url = f"https://api-krs.ms.gov.pl/api/krs/OdpisAktualny/{clean}?rejestr=P&format=json"
    else:
        url = f"https://api-krs.ms.gov.pl/api/krs/OdpisAktualny/{nip_or_name}?rejestr=P&format=json"

    try:
        resp = requests.get(url, timeout=REQUEST_TIMEOUT)
        if resp.status_code == 404:
            return {"found": False, "registry": "KRS"}
        resp.raise_for_status()
        data = resp.json()
        dane = data.get("odpis", {}).get("dane", {})
        return {
            "found": True,
            "registry": "KRS",
            "name": dane.get("nazwa", ""),
            "krs": dane.get("numerKRS", ""),
            "nip": dane.get("nip", ""),
            "regon": dane.get("regon", ""),
            "address": dane.get("adres", ""),
            "registration_date": dane.get("dataRejestracjiWKRS", ""),
            "status": "active",
        }
    except Exception as exc:
        log.warning(f"KRS lookup failed: {exc}")
        return {"found": False, "registry": "KRS", "error": str(exc)}


def _ceidg_lookup(nip_or_name: str) -> dict:
    """Check Polish CEIDG registry (sole proprietors)."""
    clean = re.sub(r"[\s-]", "", nip_or_name)
    if re.match(r"^\d{10}$", clean):
        url = f"https://dane.biznes.gov.pl/api/ceidg/v2/firma?nip={clean}"
    else:
        url = f"https://dane.biznes.gov.pl/api/ceidg/v2/firma?nazwa={nip_or_name}"

    try:
        resp = requests.get(url, timeout=REQUEST_TIMEOUT)
        if resp.status_code == 404:
            return {"found": False, "registry": "CEIDG"}
        resp.raise_for_status()
        data = resp.json()
        firmy = data.get("firmy", [])
        if not firmy:
            return {"found": False, "registry": "CEIDG"}
        f = firmy[0]
        return {
            "found": True,
            "registry": "CEIDG",
            "name": f.get("nazwa", ""),
            "nip": f.get("wlasciciel", {}).get("nip", ""),
            "status": f.get("status", ""),
            "start_date": f.get("dataRozpoczeciaDzialalnosci", ""),
            "address": f.get("adresDzialalnosci", {}).get("adres", ""),
        }
    except Exception as exc:
        log.warning(f"CEIDG lookup failed: {exc}")
        return {"found": False, "registry": "CEIDG", "error": str(exc)}


def _companies_house_lookup(query: str) -> dict:
    """Check UK Companies House registry."""
    if not COMPANIES_HOUSE_KEY:
        return {"found": False, "registry": "Companies House", "reason": "no_api_key"}
    try:
        resp = requests.get(
            f"https://api.company-information.service.gov.uk/search/companies?q={query}",
            auth=(COMPANIES_HOUSE_KEY, ""),
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        data = resp.json()
        items = data.get("items", [])
        if not items:
            return {"found": False, "registry": "Companies House"}
        c = items[0]
        return {
            "found": True,
            "registry": "Companies House",
            "name": c.get("title", ""),
            "company_number": c.get("company_number", ""),
            "status": c.get("company_status", ""),
            "date_of_creation": c.get("date_of_creation", ""),
            "address": c.get("address_snippet", ""),
            "company_type": c.get("company_type", ""),
        }
    except Exception as exc:
        log.warning(f"Companies House lookup failed: {exc}")
        return {"found": False, "registry": "Companies House", "error": str(exc)}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  RISK SCORING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SAFE_EMAIL_DOMAINS = {
    'gmail.com', 'outlook.com', 'hotmail.com', 'yahoo.com',
    'wp.pl', 'onet.pl', 'interia.pl', 'o2.pl', 'proton.me',
    'icloud.com', 'me.com', 'protonmail.com',
}


def calculate_risk(signals: dict) -> int:
    """Calculate risk score (0-100) from aggregated signals â€” bidirectional scoring.

    Positive factors increase risk, negative factors (trust signals) decrease it.
    Floor: 0, Cap: 100.
    Thresholds: <20 BEZPIECZNE, 20-50 PODEJRZANE, >50 OSZUSTWO.
    """
    score = 0

    # â”€â”€ INCREASING FACTORS â”€â”€

    # WHOIS age
    whois_data = signals.get("whois", {})
    age = whois_data.get("age_days")
    if age is not None:
        if age < 90:
            score += 40
        elif age < 365:
            score += 20

    # Domain looks available / unregistered
    if whois_data.get("available"):
        score += 30

    # Google Safe Browsing
    gsb = signals.get("google_safe_browsing", {})
    if gsb.get("flagged"):
        score += 70

    # VirusTotal
    vt = signals.get("virustotal", {})
    if vt.get("positives", 0) >= 5:
        score += 60
    elif vt.get("positives", 0) >= 2:
        score += 30

    # URLhaus
    urlhaus = signals.get("urlhaus", {})
    if urlhaus.get("blacklisted"):
        score += 50

    # GreyNoise
    gn = signals.get("greynoise", {})
    if gn.get("classification") == "malicious":
        score += 30

    # Company registry â€” not found
    company = signals.get("company", {})
    if company and not company.get("found", True):
        score += 60

    # Disposable email
    if signals.get("disposable_email"):
        score += 50

    # No MX records
    mx = signals.get("mx", {})
    if mx and not mx.get("has_mx", True):
        score += 30

    # Wayback Machine â€” very new site
    wb = signals.get("wayback", {})
    archive_age = wb.get("archive_age_days")
    if archive_age is not None and archive_age < 180:
        score += 25

    # AbuseIPDB high score
    abuse = signals.get("abuseipdb", {})
    abuse_score = abuse.get("abuseConfidenceScore", 0)
    if abuse_score > 50:
        score += 40
    elif abuse_score > 20:
        score += 20

    # OTX pulses
    otx = signals.get("otx", {})
    otx_pulses = otx.get("pulse_count", 0)
    if otx_pulses > 5:
        score += 40
    elif otx_pulses > 0:
        score += 20

    # IPinfo â€” high-risk countries
    ipinfo = signals.get("ipinfo", {})
    ipinfo_country = (ipinfo.get("country") or "").upper()
    if ipinfo_country in ("UA", "RU", "KP", "IR", "CN"):
        score += 25

    # SPF/DMARC â€” both missing
    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc and not spf_dmarc.get("has_spf") and not spf_dmarc.get("has_dmarc"):
        score += 15

    # crt.sh â€” very new cert
    crtsh = signals.get("crtsh", {})
    cert_age = crtsh.get("cert_age_days")
    if cert_age is not None and cert_age < 30:
        score += 25

    # No Tranco rank (not in top 1M)
    tranco = signals.get("tranco", {})
    if tranco.get("available") and tranco.get("rank") is None:
        score += 10

    # â”€â”€ DECREASING FACTORS (trust signals) â”€â”€

    # Tranco ranking
    tranco_rank = tranco.get("rank")
    if tranco_rank is not None:
        if tranco_rank <= 10000:
            score -= 50
        elif tranco_rank <= 100000:
            score -= 30
        elif tranco_rank <= 1000000:
            score -= 15

    # AbuseIPDB whitelisted
    if abuse.get("isWhitelisted"):
        score -= 30

    # OTX validation non-empty (domain validated / analyzed)
    if otx.get("validation") and len(otx["validation"]) > 0:
        score -= 20

    # Domain age â€” long-standing
    if age is not None:
        if age > 3650:  # >10 years
            score -= 30
        elif age > 1825:  # >5 years
            score -= 20

    # crt.sh â€” old cert (>2 years)
    if cert_age is not None and cert_age > 730:
        score -= 20

    # SPF + DMARC both present
    if spf_dmarc.get("has_spf") and spf_dmarc.get("has_dmarc"):
        score -= 10

    # Company confirmed in registry
    if company and company.get("found"):
        score -= 40

    # Safe email domain override â€” known providers cap at 15
    whois_domain = whois_data.get("domain", "").lower()
    if whois_domain in SAFE_EMAIL_DOMAINS:
        score = min(score, 15)

    return max(0, min(100, score))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  AI VERDICT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _extract_problems(signals: dict) -> list[dict]:
    """Convert red flags into structured problem cards with what_found/what_means/real_risk."""
    problems = []

    whois = signals.get("whois", {})
    age = whois.get("age_days")
    if age is not None and age < 90:
        problems.append({
            "title": "Bardzo nowa domena",
            "what_found": f"Domena zostaÅ‚a zarejestrowana zaledwie {age} dni temu.",
            "what_means": "OszuÅ›ci zakÅ‚adajÄ… nowe strony tuÅ¼ przed atakiem i porzucajÄ… je po kilku tygodniach. Legalne firmy majÄ… domeny od lat.",
            "real_risk": "Strona moÅ¼e zniknÄ…Ä‡ razem z Twoimi pieniÄ™dzmi.",
        })
    elif age is not None and age < 365:
        problems.append({
            "title": "Stosunkowo nowa domena",
            "what_found": f"Domena istnieje od {age} dni (mniej niÅ¼ rok).",
            "what_means": "Nowe domeny nie muszÄ… byÄ‡ zÅ‚oÅ›liwe, ale warto zachowaÄ‡ czujnoÅ›Ä‡ â€” wiÄ™kszoÅ›Ä‡ oszustw odbywa siÄ™ na domenach mÅ‚odszych niÅ¼ rok.",
            "real_risk": "PodwyÅ¼szone ryzyko â€” zweryfikuj firmÄ™ innymi kanaÅ‚ami.",
        })

    gsb = signals.get("google_safe_browsing", {})
    if gsb.get("flagged"):
        threats = ", ".join(gsb.get("threats", []))
        problems.append({
            "title": "Google ostrzega przed tÄ… stronÄ…",
            "what_found": f"Google Safe Browsing aktywnie blokuje tÄ™ stronÄ™. ZagroÅ¼enia: {threats}.",
            "what_means": "Google przeskanowaÅ‚ miliardy stron i oznaczyÅ‚ tÄ™ jako niebezpiecznÄ…. Twoja przeglÄ…darka powinna pokazaÄ‡ ostrzeÅ¼enie.",
            "real_risk": "WejÅ›cie na tÄ™ stronÄ™ moÅ¼e zainstalowaÄ‡ zÅ‚oÅ›liwe oprogramowanie lub wykraÅ›Ä‡ Twoje dane.",
        })

    vt = signals.get("virustotal", {})
    pos = vt.get("positives", 0)
    if pos >= 5:
        problems.append({
            "title": "Antywirusy oznaczajÄ… jako zÅ‚oÅ›liwe",
            "what_found": f"{pos} z {vt.get('total', 0)} silnikÃ³w antywirusowych oznaczyÅ‚o ten URL.",
            "what_means": "To jak gdyby kilkudziesiÄ™ciu lekarzy zbadaÅ‚o pacjenta i wiÄ™kszoÅ›Ä‡ powiedziaÅ‚a, Å¼e jest chory. JeÅ›li wiele antywirusÃ³w siÄ™ zgadza â€” to powaÅ¼ny sygnaÅ‚.",
            "real_risk": "MoÅ¼esz straciÄ‡ pieniÄ…dze lub dane osobowe.",
        })
    elif pos >= 2:
        problems.append({
            "title": "Kilka antywirusÃ³w ma zastrzeÅ¼enia",
            "what_found": f"{pos} z {vt.get('total', 0)} silnikÃ³w oznaczyÅ‚o ten URL.",
            "what_means": "Nie jest to jednoznaczne, ale kilka niezaleÅ¼nych systemÃ³w zabezpieczeÅ„ wykryÅ‚o potencjalne zagroÅ¼enie.",
            "real_risk": "Zachowaj ostroÅ¼noÅ›Ä‡ â€” nie podawaj danych osobowych.",
        })

    urlhaus = signals.get("urlhaus", {})
    if urlhaus.get("blacklisted"):
        problems.append({
            "title": "Strona na czarnej liÅ›cie",
            "what_found": "URLhaus (baza zÅ‚oÅ›liwych stron) ma tÄ™ domenÄ™ na czarnej liÅ›cie.",
            "what_means": "Ta strona byÅ‚a wczeÅ›niej wykorzystywana do rozprzestrzeniania zÅ‚oÅ›liwego oprogramowania lub phishingu.",
            "real_risk": "TwÃ³j komputer moÅ¼e zostaÄ‡ zainfekowany wirusem.",
        })

    gn = signals.get("greynoise", {})
    if gn.get("classification") == "malicious":
        problems.append({
            "title": "IP oznaczone jako zÅ‚oÅ›liwe",
            "what_found": "GreyNoise klasyfikuje adres IP serwera jako zÅ‚oÅ›liwy.",
            "what_means": "Serwer, na ktÃ³rym stoi ta strona, jest znany z podejrzanej aktywnoÅ›ci w internecie.",
            "real_risk": "Strona moÅ¼e byÄ‡ czÄ™Å›ciÄ… wiÄ™kszej sieci oszustw.",
        })

    company = signals.get("company", {})
    if company and not company.get("found", True):
        problems.append({
            "title": "Firma nie istnieje w rejestrze",
            "what_found": "Nie znaleÅºliÅ›my tej firmy w oficjalnym rejestrze KRS ani CEIDG.",
            "what_means": "KaÅ¼da legalna polska firma musi byÄ‡ zarejestrowana. JeÅ›li jej nie ma w rejestrze â€” albo podaje faÅ‚szywÄ… nazwÄ™, albo dziaÅ‚a nielegalnie.",
            "real_risk": "Nie masz Å¼adnej ochrony prawnej jeÅ›li firma CiÄ™ oszuka.",
        })

    if signals.get("disposable_email"):
        problems.append({
            "title": "Jednorazowy adres email",
            "what_found": "Domena emailowa naleÅ¼y do serwisu jednorazowych adresÃ³w.",
            "what_means": "Osoba uÅ¼ywa tymczasowego emaila, ktÃ³ry za chwilÄ™ przestanie istnieÄ‡. Legalne firmy nie uÅ¼ywajÄ… takich adresÃ³w.",
            "real_risk": "Nie bÄ™dziesz w stanie skontaktowaÄ‡ siÄ™ z nadawcÄ….",
        })

    mx = signals.get("mx", {})
    if mx and not mx.get("has_mx", True):
        problems.append({
            "title": "Domena nie obsÅ‚uguje poczty",
            "what_found": "Brak rekordÃ³w MX â€” ta domena nie moÅ¼e wysyÅ‚aÄ‡ ani odbieraÄ‡ emaili.",
            "what_means": "JeÅ›li firma twierdzi, Å¼e kontakt jest przez email na tej domenie â€” kÅ‚amie.",
            "real_risk": "Odpowiedzi na emaile nie dotrÄ… do nikogo.",
        })

    abuse = signals.get("abuseipdb", {})
    if abuse.get("abuseConfidenceScore", 0) > 20:
        problems.append({
            "title": "IP zgÅ‚aszane za naduÅ¼ycia",
            "what_found": f"AbuseIPDB: {abuse['abuseConfidenceScore']}% pewnoÅ›ci naduÅ¼yÄ‡, {abuse.get('totalReports', 0)} zgÅ‚oszeÅ„.",
            "what_means": "Inni internauci zgÅ‚aszali problemy z tym adresem IP â€” spam, ataki, oszustwa.",
            "real_risk": "Serwer ma zÅ‚Ä… reputacjÄ™ w spoÅ‚ecznoÅ›ci bezpieczeÅ„stwa.",
        })

    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc and not spf_dmarc.get("has_spf") and not spf_dmarc.get("has_dmarc"):
        problems.append({
            "title": "Brak ochrony przed podszywaniem",
            "what_found": "Domena nie ma zabezpieczeÅ„ SPF ani DMARC.",
            "what_means": "Ktokolwiek moÅ¼e wysyÅ‚aÄ‡ emaile udajÄ…c, Å¼e jest z tej domeny. To jak gdyby firma nie miaÅ‚a pieczÄ…tki.",
            "real_risk": "MoÅ¼esz dostaÄ‡ faÅ‚szywy email wyglÄ…dajÄ…cy jak od tej firmy.",
        })

    crtsh = signals.get("crtsh", {})
    if crtsh.get("cert_age_days") is not None and crtsh["cert_age_days"] < 30:
        problems.append({
            "title": "Bardzo nowy certyfikat SSL",
            "what_found": f"Certyfikat SSL wystawiony {crtsh['cert_age_days']} dni temu.",
            "what_means": "OszuÅ›ci uzyskujÄ… certyfikaty SSL tuÅ¼ przed atakiem, Å¼eby strona wyglÄ…daÅ‚a na bezpiecznÄ… (kÅ‚Ã³dka w przeglÄ…darce).",
            "real_risk": "KÅ‚Ã³dka w przeglÄ…darce NIE gwarantuje bezpieczeÅ„stwa.",
        })

    otx = signals.get("otx", {})
    if otx.get("pulse_count", 0) > 0:
        problems.append({
            "title": "Widoczna w raportach zagroÅ¼eÅ„",
            "what_found": f"OTX AlienVault: {otx['pulse_count']} raportÃ³w threat intelligence.",
            "what_means": "Eksperci ds. bezpieczeÅ„stwa analizowali tÄ™ domenÄ™ i powiÄ…zali jÄ… z zagroÅ¼eniami.",
            "real_risk": "Domena jest znana w Å›wiecie cyberbezpieczeÅ„stwa jako podejrzana.",
        })

    return problems


def _extract_positives(signals: dict) -> list[dict]:
    """Convert trust factors into structured positive cards with what_found/what_means."""
    positives = []

    tranco = signals.get("tranco", {})
    rank = tranco.get("rank")
    if rank is not None:
        if rank <= 10000:
            positives.append({
                "title": "Popularna strona",
                "what_found": f"Domena jest na pozycji #{rank} w rankingu Tranco (top 10K).",
                "what_means": "To jedna z najpopularniejszych stron w internecie â€” miliony ludzi z niej korzystajÄ….",
            })
        elif rank <= 100000:
            positives.append({
                "title": "Znana strona",
                "what_found": f"Domena jest na pozycji #{rank} w rankingu Tranco.",
                "what_means": "Strona ma spory ruch â€” to dobry znak, bo oszuÅ›ci rzadko osiÄ…gajÄ… takÄ… popularnoÅ›Ä‡.",
            })

    whois = signals.get("whois", {})
    age = whois.get("age_days")
    if age is not None and age > 3650:
        positives.append({
            "title": "Domena od wielu lat",
            "what_found": f"Domena istnieje od {age // 365} lat.",
            "what_means": "DÅ‚ugo dziaÅ‚ajÄ…ce domeny to dobry znak â€” oszuÅ›ci porzucajÄ… strony po kilku miesiÄ…cach.",
        })
    elif age is not None and age > 1825:
        positives.append({
            "title": "Ugruntowana domena",
            "what_found": f"Domena istnieje od {age // 365} lat.",
            "what_means": "Kilka lat dziaÅ‚alnoÅ›ci buduje zaufanie.",
        })

    abuse = signals.get("abuseipdb", {})
    if abuse.get("isWhitelisted"):
        positives.append({
            "title": "IP na biaÅ‚ej liÅ›cie",
            "what_found": "AbuseIPDB uznaje ten adres IP za zaufany.",
            "what_means": "Serwer jest oficjalnie uznawany za bezpieczny przez spoÅ‚ecznoÅ›Ä‡ bezpieczeÅ„stwa.",
        })

    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc.get("has_spf") and spf_dmarc.get("has_dmarc"):
        positives.append({
            "title": "Ochrona przed spoofingiem",
            "what_found": "Domena ma skonfigurowane zabezpieczenia SPF + DMARC.",
            "what_means": "Firma dba o bezpieczeÅ„stwo emaili â€” nikt nie moÅ¼e siÄ™ pod niÄ… podszywaÄ‡.",
        })

    company = signals.get("company", {})
    if company and company.get("found"):
        registry = company.get("registry", "rejestr")
        positives.append({
            "title": "Firma w oficjalnym rejestrze",
            "what_found": f"Firma potwierdzona w {registry}.",
            "what_means": "Firma jest oficjalnie zarejestrowana, co oznacza Å¼e podlega polskiemu prawu i moÅ¼na jÄ… pociÄ…gnÄ…Ä‡ do odpowiedzialnoÅ›ci.",
        })

    crtsh = signals.get("crtsh", {})
    cert_age = crtsh.get("cert_age_days")
    if cert_age is not None and cert_age > 730:
        positives.append({
            "title": "DÅ‚ugotrwaÅ‚y certyfikat SSL",
            "what_found": f"Certyfikat SSL od {cert_age // 365} lat.",
            "what_means": "Strona od dawna dba o szyfrowanie â€” to dobra praktyka.",
        })

    return positives


def _generate_action(risk_score: int, query: str) -> str:
    """Generate concrete action recommendation based on risk score."""
    if risk_score > 50:
        return f"Nie wchodÅº na {query}. JeÅ›li ktoÅ› przysÅ‚aÅ‚ Ci ten link â€” zignoruj wiadomoÅ›Ä‡. JeÅ›li podaÅ‚eÅ› dane, natychmiast zmieÅ„ hasÅ‚a i skontaktuj siÄ™ z bankiem."
    elif risk_score >= 20:
        return f"Zachowaj ostroÅ¼noÅ›Ä‡. Nie podawaj danych osobowych ani finansowych na {query}. SprawdÅº adres URL dokÅ‚adnie â€” czy to na pewno oficjalna strona?"
    else:
        return f"Strona {query} wyglÄ…da bezpiecznie. PamiÄ™taj jednak, aby zawsze sprawdzaÄ‡ adres URL przed podaniem danych."


def _generate_immediate_actions(risk_score: int, query: str) -> list[str]:
    """Generate numbered list of immediate actions."""
    if risk_score > 50:
        return [
            f"Nie wchodÅº na {query} â€” zamknij kartÄ™ jeÅ›li jest otwarta",
            "JeÅ›li kliknÄ…Å‚eÅ› link â€” uruchom skanowanie antywirusowe na komputerze",
            "JeÅ›li podaÅ‚eÅ› login/hasÅ‚o â€” natychmiast zmieÅ„ hasÅ‚o na tej i innych stronach gdzie uÅ¼ywasz tego samego",
            "OstrzeÅ¼ osobÄ™, ktÃ³ra przysÅ‚aÅ‚a Ci ten link â€” jej konto mogÅ‚o zostaÄ‡ przejÄ™te",
        ]
    elif risk_score >= 20:
        return [
            f"Nie podawaj Å¼adnych danych osobowych ani finansowych na {query}",
            "SprawdÅº adres URL literka po literce â€” czy to na pewno oficjalna strona?",
            "Poszukaj opinii o tej firmie w Google â€” dopisz sÅ‚owo 'oszustwo' lub 'opinie'",
            "JeÅ›li chcesz coÅ› kupiÄ‡ â€” szukaj tej samej oferty na znanych portalach (Allegro, OLX)",
        ]
    else:
        return [
            "Strona wyglÄ…da bezpiecznie â€” moÅ¼esz z niej korzystaÄ‡",
            "Mimo to zawsze sprawdzaj adres URL przed podaniem danych",
            "UÅ¼ywaj silnych, unikalnych haseÅ‚ na kaÅ¼dej stronie",
        ]


def _generate_if_paid_already(risk_score: int) -> list[str]:
    """Generate steps for when user already paid/shared data."""
    if risk_score > 50:
        return [
            "Natychmiast zadzwoÅ„ do swojego banku i zablokuj kartÄ™/konto",
            "ZmieÅ„ hasÅ‚a â€” zacznij od banku, potem email, potem reszta",
            "WÅ‚Ä…cz weryfikacjÄ™ dwuetapowÄ… (2FA) wszÄ™dzie gdzie to moÅ¼liwe",
            "ZgÅ‚oÅ› sprawÄ™ na policjÄ™ i do CERT Polska (incydent.cert.pl)",
            "Monitoruj wyciÄ…gi bankowe przez najbliÅ¼sze 30 dni",
        ]
    elif risk_score >= 20:
        return [
            "SprawdÅº wyciÄ…g bankowy â€” czy sÄ… nieautoryzowane transakcje",
            "ZmieÅ„ hasÅ‚o jeÅ›li podaÅ‚eÅ› je na tej stronie",
            "JeÅ›li podaÅ‚eÅ› dane karty â€” skontaktuj siÄ™ z bankiem",
            "Zachowaj dowody (screenshoty, emaile) na wypadek reklamacji",
        ]
    else:
        return []


def _generate_report_to(risk_score: int) -> list[dict]:
    """Generate list of institutions to report fraud to."""
    if risk_score <= 20:
        return []
    institutions = []
    if risk_score > 50:
        institutions.append({
            "institution": "CERT Polska",
            "url": "https://incydent.cert.pl",
            "description": "ZgÅ‚oÅ› stronÄ™ phishingowÄ… lub oszustwo internetowe. CERT doda jÄ… do listy ostrzeÅ¼eÅ„.",
        })
        institutions.append({
            "institution": "Policja â€” cyberprzestÄ™pczoÅ›Ä‡",
            "url": "https://www.policja.pl/pol/zgloszenie",
            "description": "ZÅ‚Ã³Å¼ oficjalne zawiadomienie o przestÄ™pstwie. BÄ™dziesz potrzebowaÄ‡ screenshotÃ³w i dowodÃ³w wpÅ‚aty.",
        })
    institutions.append({
        "institution": "UOKiK",
        "url": "https://uokik.gov.pl/kontakt",
        "description": "ZgÅ‚oÅ› nieuczciwÄ… praktykÄ™ handlowÄ…. UOKiK moÅ¼e naÅ‚oÅ¼yÄ‡ karÄ™ na firmÄ™.",
    })
    institutions.append({
        "institution": "TwÃ³j bank",
        "url": "",
        "description": "ZadzwoÅ„ na infoliniÄ™ banku i poproÅ› o procedurÄ™ chargeback (zwrot pieniÄ™dzy za oszustwo).",
    })
    return institutions


def _generate_narrative(risk_score: int, signals: dict, query: str) -> str:
    """Generate a warm, educational narrative about the verification result."""
    problems = _extract_problems(signals)
    positives = _extract_positives(signals)

    if risk_score > 50:
        intro = f"SprawdziliÅ›my {query} w {len(signals)} niezaleÅ¼nych bazach danych bezpieczeÅ„stwa i mamy powaÅ¼ne obawy."
        detail = f" ZnaleÅºliÅ›my {len(problems)} sygnaÅ‚Ã³w ostrzegawczych." if problems else ""
        advice = " Zdecydowanie odradzamy interakcjÄ™ z tÄ… stronÄ… â€” wiele wskazuje na to, Å¼e moÅ¼e byÄ‡ niebezpieczna."
        outro = " JeÅ›li otrzymaÅ‚eÅ› ten link w wiadomoÅ›ci od kogoÅ› â€” nie klikaj i ostrzeÅ¼ nadawcÄ™, bo jego konto mogÅ‚o zostaÄ‡ przejÄ™te."
    elif risk_score >= 20:
        intro = f"SprawdziliÅ›my {query} i znaleÅºliÅ›my mieszane sygnaÅ‚y."
        detail = f" Z jednej strony {len(positives)} czynnikÃ³w wyglÄ…da dobrze, ale {len(problems)} budzi nasze wÄ…tpliwoÅ›ci." if positives and problems else ""
        advice = " Nie oznacza to od razu oszustwa, ale zalecamy zachowanie czujnoÅ›ci."
        outro = " Zanim podasz jakiekolwiek dane, upewnij siÄ™ Å¼e to oficjalna strona firmy, z ktÃ³rÄ… chcesz mieÄ‡ do czynienia."
    else:
        intro = f"SprawdziliÅ›my {query} w naszych bazach bezpieczeÅ„stwa i wszystko wyglÄ…da w porzÄ…dku."
        detail = f" ZnaleÅºliÅ›my {len(positives)} pozytywnych sygnaÅ‚Ã³w zaufania." if positives else ""
        advice = " Strona ma dobre wskaÅºniki bezpieczeÅ„stwa."
        outro = " PamiÄ™taj jednak, Å¼e Å¼adna automatyczna analiza nie daje 100% pewnoÅ›ci â€” zawsze warto zachowaÄ‡ zdrowy rozsÄ…dek."

    return intro + detail + advice + outro


def _generate_educational_tips(risk_score: int, signals: dict) -> list[dict]:
    """Generate structured educational tips based on analysis."""
    tips = []

    whois = signals.get("whois", {})
    if whois.get("age_days") is not None:
        tips.append({
            "icon": "ğŸ“…",
            "title": "Sprawdzaj wiek domeny",
            "text": "Legalne firmy dziaÅ‚ajÄ… od lat. JeÅ›li domena ma mniej niÅ¼ 90 dni â€” to powaÅ¼ny sygnaÅ‚ ostrzegawczy.",
            "example": "NastÄ™pnym razem wpisz nazwÄ™ strony na whois.domaintools.com â€” zobaczysz kiedy zostaÅ‚a zarejestrowana.",
        })

    spf = signals.get("spf_dmarc", {})
    if spf:
        tips.append({
            "icon": "ğŸ“§",
            "title": "SPF i DMARC chroniÄ… przed faÅ‚szywymi emailami",
            "text": "To jak pieczÄ…tka na liÅ›cie â€” potwierdza, Å¼e email naprawdÄ™ pochodzi z tej firmy. Bez SPF i DMARC ktokolwiek moÅ¼e udawaÄ‡ danÄ… firmÄ™.",
            "example": "JeÅ›li dostaniesz email 'z banku' â€” sprawdÅº czy bank ma SPF/DMARC. WiÄ™kszoÅ›Ä‡ duÅ¼ych firm je ma.",
        })

    if signals.get("virustotal", {}).get("available"):
        tips.append({
            "icon": "ğŸ”",
            "title": "Jak samodzielnie sprawdziÄ‡ link?",
            "text": "Wklej podejrzany link na virustotal.com â€” 70+ silnikÃ³w antywirusowych sprawdzi go za darmo. Nigdy nie klikaj linku, zanim go nie zweryfikujesz.",
            "example": "Kopiuj link (prawy przycisk â†’ Kopiuj adres linku) i wklej na virustotal.com zamiast klikaÄ‡.",
        })

    if signals.get("tranco", {}):
        tips.append({
            "icon": "ğŸ“Š",
            "title": "Ranking popularnoÅ›ci stron",
            "text": "Tranco to niezaleÅ¼ny ranking miliona najpopularniejszych stron. JeÅ›li strona jest w top 10K â€” prawie na pewno jest legalna.",
            "example": "Google.com jest w top 10, Allegro.pl w top 1000. Nowa strona z ofertÄ… 'za dobrÄ… Å¼eby byÅ‚a prawdziwa' raczej nie bÄ™dzie w rankingu.",
        })

    if risk_score > 50:
        tips.append({
            "icon": "ğŸš¨",
            "title": "Co zrobiÄ‡ gdy podaÅ‚eÅ› dane?",
            "text": "Natychmiast zmieÅ„ hasÅ‚a (zacznij od banku i emaila). WÅ‚Ä…cz weryfikacjÄ™ dwuetapowÄ… (2FA). ZgÅ‚oÅ› incydent na incydent.cert.pl.",
            "example": "Zainstaluj aplikacjÄ™ do 2FA (np. Google Authenticator) â€” nawet jeÅ›li ktoÅ› pozna Twoje hasÅ‚o, nie zaloguje siÄ™ bez kodu z telefonu.",
        })

    if len(tips) < 3:
        tips.append({
            "icon": "ğŸ”’",
            "title": "KÅ‚Ã³dka nie oznacza bezpieczeÅ„stwa",
            "text": "KÅ‚Ã³dka w pasku adresu oznacza szyfrowane poÅ‚Ä…czenie, ale NIE gwarantuje, Å¼e strona jest bezpieczna. OszuÅ›ci teÅ¼ uÅ¼ywajÄ… HTTPS.",
            "example": "Patrz na adres obok kÅ‚Ã³dki: allegro.pl jest OK, ale allegro-promocja.xyz to oszustwo â€” mimo Å¼e oba majÄ… kÅ‚Ã³dkÄ™.",
        })

    return tips[:5]


def generate_verdict(risk_score: int, signals: dict, query: str) -> dict:
    """Generate AI verdict using Claude Haiku â€” educational mode for non-tech users."""
    # Determine base verdict from score (new thresholds)
    if risk_score < 20:
        base_verdict = "BEZPIECZNE"
    elif risk_score <= 50:
        base_verdict = "PODEJRZANE"
    else:
        base_verdict = "OSZUSTWO"

    # Try AI-enhanced verdict
    try:
        from modules.llm_provider import ClaudeProvider
        provider = ClaudeProvider(model="claude-haiku-4-5-20251001")

        signals_summary = json.dumps(signals, ensure_ascii=False, default=str)
        if len(signals_summary) > 2000:
            signals_summary = signals_summary[:2000] + '... (skrÃ³cono)"'

        prompt = (
            f"JesteÅ› ekspertem od bezpieczeÅ„stwa online. Piszesz raport dla osoby "
            f"bez wiedzy technicznej â€” np. emeryta ktÃ³ry szuka samochodu online.\n\n"
            f"Dane weryfikacji:\n{signals_summary}\n"
            f"Risk score: {risk_score}/100 (progi: <20 bezpieczne, 20-50 podejrzane, >50 oszustwo)\n"
            f"Sprawdzana domena: {query}\n\n"
            f"ZwrÃ³Ä‡ WYÅÄ„CZNIE JSON (bez markdown, wszystkie pola PO POLSKU):\n"
            f'{{"verdict": "{base_verdict}", '
            f'"summary": "3-4 zdania. Powiedz CO konkretnie znalazÅ‚eÅ› i DLACZEGO to niepokojÄ…ce lub bezpieczne. Nie uÅ¼ywaj Å¼argonu technicznego.", '
            f'"narrative": "4-6 zdaÅ„ ciepÅ‚ym jÄ™zykiem â€” co sprawdziliÅ›my, co znaleÅºliÅ›my, co to oznacza", '
            f'"red_flags": ["lista flag po polsku"], '
            f'"trust_factors": ["lista czynnikÃ³w zaufania"], '
            f'"signal_explanations": [{{"signal": "nazwa", "value": "wartoÅ›Ä‡", "meaning": "co to znaczy po polsku", "risk": "green|gray|amber|red", "icon": "emoji"}}], '
            f'"problems": [{{"title": "KrÃ³tka nazwa problemu", "what_found": "Co technicznie znalazÅ‚eÅ› - 1 zdanie", "what_means": "Co to oznacza dla zwykÅ‚ego czÅ‚owieka - 1-2 zdania", "real_risk": "Konkretne ryzyko np. MoÅ¼esz straciÄ‡ pieniÄ…dze"}}], '
            f'"positives": [{{"title": "KrÃ³tka nazwa pozytywu", "what_found": "Co znalazÅ‚eÅ› - 1 zdanie", "what_means": "Dlaczego to dobry znak - 1 zdanie"}}], '
            f'"immediate_actions": ["Natychmiastowe dziaÅ‚anie 1 - konkretne i wykonalne", "DziaÅ‚anie 2", "DziaÅ‚anie 3"], '
            f'"if_paid_already": ["Co zrobiÄ‡ jeÅ›li juÅ¼ zapÅ‚aciÅ‚eÅ› krok 1", "Krok 2"], '
            f'"report_to": [{{"institution": "Nazwa instytucji", "url": "adres strony", "description": "Co tam zgÅ‚osiÄ‡ i po co"}}], '
            f'"educational_tips": [{{"icon": "emoji", "title": "TytuÅ‚ wskazÃ³wki", "text": "2-3 zdania edukacyjne", "example": "Konkretny przykÅ‚ad jak zastosowaÄ‡ tÄ™ wiedzÄ™"}}], '
            f'"recommendation": "Rekomendacja 1-2 zdania"}}\n\n'
            f"WAÅ»NE:\n"
            f"- Dla OSZUSTWA: report_to musi zawieraÄ‡ CERT Polska (incydent.cert.pl), PolicjÄ™, UOKiK, bank\n"
            f"- Dla PODEJRZANE: daj konkretne kroki jak zweryfikowaÄ‡ rÄ™cznie\n"
            f"- if_paid_already wypeÅ‚nij zawsze dla OSZUSTWO i PODEJRZANE\n"
            f"- Pisz jakbyÅ› rozmawiaÅ‚ z osobÄ… starszÄ… ktÃ³ra nie zna siÄ™ na technologii"
        )

        response_text = provider.chat(prompt, max_tokens=2500)
        clean = response_text.strip()
        if clean.startswith("```"):
            clean = clean.split("```")[1]
            if clean.startswith("json"):
                clean = clean[4:]

        def _repair_json(text: str) -> dict:
            """Try to parse JSON with progressive repair strategies."""
            text = text.strip()
            # Strategy 1: direct parse
            try:
                return json.loads(text)
            except json.JSONDecodeError:
                pass
            # Strategy 2: remove trailing commas
            repaired = re.sub(r',(\s*[}\]])', r'\1', text)
            try:
                return json.loads(repaired)
            except json.JSONDecodeError:
                pass
            # Strategy 3: extract outermost { ... }
            start = text.find("{")
            end = text.rfind("}") + 1
            if start >= 0 and end > start:
                fragment = text[start:end]
                try:
                    return json.loads(fragment)
                except json.JSONDecodeError:
                    # Try repair on fragment too
                    repaired_frag = re.sub(r',(\s*[}\]])', r'\1', fragment)
                    try:
                        return json.loads(repaired_frag)
                    except json.JSONDecodeError:
                        pass
            raise json.JSONDecodeError("All repair strategies failed", text, 0)

        result = _repair_json(clean)

        # Ensure verdict matches score-based threshold
        result["verdict"] = base_verdict
        # Ensure all fields present with fallbacks
        result.setdefault("trust_factors", _extract_trust_factors(signals))
        result.setdefault("signal_explanations", _extract_signal_explanations(signals))
        result.setdefault("narrative", _generate_narrative(risk_score, signals, query))
        result.setdefault("problems", _extract_problems(signals))
        result.setdefault("positives", _extract_positives(signals))
        result.setdefault("action", _generate_action(risk_score, query))
        result.setdefault("immediate_actions", _generate_immediate_actions(risk_score, query))
        result.setdefault("if_paid_already", _generate_if_paid_already(risk_score))
        result.setdefault("report_to", _generate_report_to(risk_score))
        result.setdefault("educational_tips", _generate_educational_tips(risk_score, signals))
        # Normalize educational_tips to dict format
        tips = result.get("educational_tips", [])
        if tips and isinstance(tips[0], str):
            result["educational_tips"] = [{"icon": "ğŸ’¡", "title": "Porada", "text": t, "example": ""} for t in tips]
        return result

    except Exception as exc:
        log.warning(f"AI verdict generation failed: {exc}")
        return {
            "verdict": base_verdict,
            "summary": f"Analiza automatyczna wykazaÅ‚a risk score {risk_score}/100.",
            "narrative": _generate_narrative(risk_score, signals, query),
            "red_flags": _extract_red_flags(signals),
            "trust_factors": _extract_trust_factors(signals),
            "signal_explanations": _extract_signal_explanations(signals),
            "problems": _extract_problems(signals),
            "positives": _extract_positives(signals),
            "action": _generate_action(risk_score, query),
            "immediate_actions": _generate_immediate_actions(risk_score, query),
            "if_paid_already": _generate_if_paid_already(risk_score),
            "report_to": _generate_report_to(risk_score),
            "educational_tips": _generate_educational_tips(risk_score, signals),
            "recommendation": "Zalecamy ostroÅ¼noÅ›Ä‡." if risk_score >= 20 else "Brak podejrzanych sygnaÅ‚Ã³w.",
        }


def _extract_red_flags(signals: dict) -> list[str]:
    """Extract human-readable red flags from signals."""
    flags = []
    whois = signals.get("whois", {})
    age = whois.get("age_days")
    if age is not None and age < 90:
        flags.append(f"WHOIS: domena zarejestrowana {age} dni temu (bardzo nowa)")
    elif age is not None and age < 365:
        flags.append(f"WHOIS: domena zarejestrowana {age} dni temu (stosunkowo nowa)")
    if whois.get("available"):
        flags.append("WHOIS: domena wyglÄ…da na niezarejestrowanÄ…")

    gsb = signals.get("google_safe_browsing", {})
    if gsb.get("flagged"):
        flags.append(f"Google Safe Browsing: {', '.join(gsb.get('threats', []))}")

    vt = signals.get("virustotal", {})
    if vt.get("positives", 0) > 0:
        flags.append(f"VirusTotal: {vt['positives']}/{vt.get('total', 0)} silnikÃ³w oznaczyÅ‚o jako zÅ‚oÅ›liwe")

    urlhaus = signals.get("urlhaus", {})
    if urlhaus.get("blacklisted"):
        flags.append("URLhaus: domena na czarnej liÅ›cie")

    gn = signals.get("greynoise", {})
    if gn.get("classification") == "malicious":
        flags.append("GreyNoise: IP oznaczone jako zÅ‚oÅ›liwe")

    company = signals.get("company", {})
    if company and not company.get("found", True):
        flags.append("Rejestr: firma nie znaleziona w rejestrze")

    if signals.get("disposable_email"):
        flags.append("Email: domena jednorazowego uÅ¼ytku (disposable)")

    mx = signals.get("mx", {})
    if mx and not mx.get("has_mx", True):
        flags.append("MX: brak rekordÃ³w (domena nie obsÅ‚uguje poczty)")

    wb = signals.get("wayback", {})
    if wb.get("archive_age_days") is not None and wb["archive_age_days"] < 180:
        flags.append(f"Wayback: strona w archiwum od {wb['archive_age_days']} dni")

    # New sources
    abuse = signals.get("abuseipdb", {})
    if abuse.get("abuseConfidenceScore", 0) > 20:
        flags.append(f"AbuseIPDB: wynik zaufania {abuse['abuseConfidenceScore']}% ({abuse.get('totalReports', 0)} zgÅ‚oszeÅ„)")

    otx = signals.get("otx", {})
    if otx.get("pulse_count", 0) > 0:
        flags.append(f"OTX: {otx['pulse_count']} pulsÃ³w threat intelligence")

    ipinfo = signals.get("ipinfo", {})
    if (ipinfo.get("country") or "").upper() in ("UA", "RU", "KP", "IR", "CN"):
        flags.append(f"IPinfo: hosting w kraju podwyÅ¼szonego ryzyka ({ipinfo['country']})")

    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc and not spf_dmarc.get("has_spf") and not spf_dmarc.get("has_dmarc"):
        flags.append("DNS: brak SPF i DMARC (brak ochrony przed spoofingiem)")

    crtsh = signals.get("crtsh", {})
    if crtsh.get("cert_age_days") is not None and crtsh["cert_age_days"] < 30:
        flags.append(f"crt.sh: certyfikat SSL wystawiony {crtsh['cert_age_days']} dni temu")

    return flags


def _extract_trust_factors(signals: dict) -> list[str]:
    """Extract trust-positive factors from signals."""
    factors = []

    tranco = signals.get("tranco", {})
    rank = tranco.get("rank")
    if rank is not None:
        if rank <= 10000:
            factors.append(f"Tranco: domena w top 10K najpopularniejszych stron (pozycja {rank})")
        elif rank <= 100000:
            factors.append(f"Tranco: domena w top 100K popularnych stron (pozycja {rank})")
        elif rank <= 1000000:
            factors.append(f"Tranco: domena w top 1M stron (pozycja {rank})")

    whois = signals.get("whois", {})
    age = whois.get("age_days")
    if age is not None:
        if age > 3650:
            factors.append(f"WHOIS: domena zarejestrowana od {age // 365} lat (stabilna)")
        elif age > 1825:
            factors.append(f"WHOIS: domena zarejestrowana od {age // 365} lat")

    abuse = signals.get("abuseipdb", {})
    if abuse.get("isWhitelisted"):
        factors.append("AbuseIPDB: IP na biaÅ‚ej liÅ›cie (zaufane)")

    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc.get("has_spf") and spf_dmarc.get("has_dmarc"):
        factors.append("DNS: SPF + DMARC skonfigurowane (ochrona przed spoofingiem)")

    company = signals.get("company", {})
    if company and company.get("found"):
        registry = company.get("registry", "rejestr")
        factors.append(f"Rejestr: firma potwierdzona w {registry}")

    crtsh = signals.get("crtsh", {})
    cert_age = crtsh.get("cert_age_days")
    if cert_age is not None and cert_age > 730:
        factors.append(f"crt.sh: certyfikat SSL od {cert_age // 365} lat (dÅ‚ugotrwaÅ‚y)")

    otx = signals.get("otx", {})
    if otx.get("validation") and len(otx["validation"]) > 0:
        factors.append("OTX: domena poddana walidacji threat intelligence")

    return factors


def _extract_signal_explanations(signals: dict) -> list[dict]:
    """Generate per-signal explanations for educational purposes."""
    explanations = []

    def _add(signal: str, value: str, meaning: str, risk: str, icon: str):
        explanations.append({"signal": signal, "value": value, "meaning": meaning, "risk": risk, "icon": icon})

    # WHOIS
    whois = signals.get("whois", {})
    age = whois.get("age_days")
    if age is not None:
        if age < 90:
            _add("WHOIS wiek", f"{age} dni", "Bardzo nowa domena â€” oszuÅ›ci czÄ™sto rejestrujÄ… domeny tuÅ¼ przed atakiem", "red", "ğŸ”´")
        elif age < 365:
            _add("WHOIS wiek", f"{age} dni", "Stosunkowo nowa domena â€” warto zachowaÄ‡ czujnoÅ›Ä‡", "amber", "ğŸŸ¡")
        elif age > 3650:
            _add("WHOIS wiek", f"{age // 365} lat", "DÅ‚ugo dziaÅ‚ajÄ…ca domena â€” to dobry znak zaufania", "green", "ğŸŸ¢")
        else:
            _add("WHOIS wiek", f"{age} dni", "Domena o umiarkowanym staÅ¼u", "gray", "âšª")

    # GSB
    gsb = signals.get("google_safe_browsing", {})
    if gsb.get("available"):
        if gsb.get("flagged"):
            _add("Google Safe Browsing", "OZNACZONE", "Google aktywnie ostrzega przed tÄ… stronÄ…", "red", "ğŸ”´")
        else:
            _add("Google Safe Browsing", "Czyste", "Google nie znalazÅ‚ zagroÅ¼eÅ„ na tej stronie", "green", "ğŸŸ¢")

    # VT
    vt = signals.get("virustotal", {})
    if vt.get("available"):
        pos = vt.get("positives", 0)
        total = vt.get("total", 0)
        if pos >= 5:
            _add("VirusTotal", f"{pos}/{total}", "Wiele silnikÃ³w antywirusowych oznaczyÅ‚o ten URL jako niebezpieczny", "red", "ğŸ”´")
        elif pos >= 2:
            _add("VirusTotal", f"{pos}/{total}", "Kilka silnikÃ³w antywirusowych ma zastrzeÅ¼enia", "amber", "ğŸŸ¡")
        elif pos > 0:
            _add("VirusTotal", f"{pos}/{total}", "Pojedyncze oznaczenie â€” moÅ¼e byÄ‡ faÅ‚szywy alarm", "gray", "âšª")
        else:
            _add("VirusTotal", f"0/{total}", "Å»aden silnik antywirusowy nie znalazÅ‚ zagroÅ¼eÅ„", "green", "ğŸŸ¢")

    # Tranco
    tranco = signals.get("tranco", {})
    rank = tranco.get("rank")
    if tranco.get("available"):
        if rank is not None:
            _add("Tranco Ranking", f"#{rank}", f"Domena jest w top {rank} najpopularniejszych stron â€” to wskazuje na legitymalnoÅ›Ä‡", "green", "ğŸŸ¢")
        else:
            _add("Tranco Ranking", "Brak w rankingu", "Domena nie jest w top 1M popularnych stron", "gray", "âšª")

    # AbuseIPDB
    abuse = signals.get("abuseipdb", {})
    if abuse.get("available"):
        ascore = abuse.get("abuseConfidenceScore", 0)
        if ascore > 50:
            _add("AbuseIPDB", f"{ascore}%", "Wysokie prawdopodobieÅ„stwo naduÅ¼yÄ‡ z tego IP", "red", "ğŸ”´")
        elif ascore > 20:
            _add("AbuseIPDB", f"{ascore}%", "Umiarkowana liczba zgÅ‚oszeÅ„ naduÅ¼yÄ‡ z tego IP", "amber", "ğŸŸ¡")
        elif abuse.get("isWhitelisted"):
            _add("AbuseIPDB", "Whitelisted", "IP jest na biaÅ‚ej liÅ›cie â€” zaufane ÅºrÃ³dÅ‚o", "green", "ğŸŸ¢")
        else:
            _add("AbuseIPDB", f"{ascore}%", "Brak znaczÄ…cych zgÅ‚oszeÅ„ naduÅ¼yÄ‡", "green", "ğŸŸ¢")

    # OTX
    otx = signals.get("otx", {})
    if otx.get("available"):
        pulses = otx.get("pulse_count", 0)
        if pulses > 5:
            _add("OTX AlienVault", f"{pulses} pulsÃ³w", "Domena pojawia siÄ™ w wielu raportach o zagroÅ¼eniach", "red", "ğŸ”´")
        elif pulses > 0:
            _add("OTX AlienVault", f"{pulses} pulsÃ³w", "Domena pojawiÅ‚a siÄ™ w raportach threat intelligence", "amber", "ğŸŸ¡")
        else:
            _add("OTX AlienVault", "0 pulsÃ³w", "Brak raportÃ³w o zagroÅ¼eniach zwiÄ…zanych z tÄ… domenÄ…", "green", "ğŸŸ¢")

    # SPF/DMARC
    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc:
        has_spf = spf_dmarc.get("has_spf", False)
        has_dmarc = spf_dmarc.get("has_dmarc", False)
        if has_spf and has_dmarc:
            _add("SPF + DMARC", "Oba skonfigurowane", "Domena chroni przed podszywaniem siÄ™ (spoofingiem)", "green", "ğŸŸ¢")
        elif has_spf or has_dmarc:
            parts = []
            if has_spf:
                parts.append("SPF")
            if has_dmarc:
                parts.append("DMARC")
            _add("SPF/DMARC", " + ".join(parts), "CzÄ™Å›ciowa ochrona przed spoofingiem", "gray", "âšª")
        else:
            _add("SPF/DMARC", "Brak", "Domena nie chroni przed podszywaniem siÄ™ pod nadawcÄ™", "amber", "ğŸŸ¡")

    # crt.sh
    crtsh = signals.get("crtsh", {})
    cert_age = crtsh.get("cert_age_days")
    if cert_age is not None:
        if cert_age < 30:
            _add("Certyfikat SSL", f"{cert_age} dni", "Bardzo nowy certyfikat â€” oszuÅ›ci czÄ™sto uzyskujÄ… SSL tuÅ¼ przed atakiem", "red", "ğŸ”´")
        elif cert_age > 730:
            _add("Certyfikat SSL", f"{cert_age // 365} lat", "DÅ‚ugotrwaÅ‚y certyfikat â€” dobry znak", "green", "ğŸŸ¢")
        else:
            _add("Certyfikat SSL", f"{cert_age} dni", "Certyfikat o standardowym wieku", "gray", "âšª")

    # IPinfo
    ipinfo = signals.get("ipinfo", {})
    if ipinfo.get("available"):
        country = (ipinfo.get("country") or "").upper()
        if country in ("UA", "RU", "KP", "IR", "CN"):
            _add("IPinfo", f"{ipinfo.get('org', '')} ({country})", "Hosting w kraju podwyÅ¼szonego ryzyka cybernetycznego", "amber", "ğŸŸ¡")
        else:
            _add("IPinfo", f"{ipinfo.get('org', '')} ({country})", "Lokalizacja serwera", "gray", "âšª")

    return explanations


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MAIN VERIFY METHODS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CyrberVerify:
    """Main verification engine."""

    def verify_url(self, url: str) -> dict:
        """Verify a URL for fraud signals."""
        if not url.startswith("http"):
            url = "https://" + url

        domain = _extract_domain(url)
        ip = _resolve_domain_ip(domain)

        signals = {}

        # WHOIS
        signals["whois"] = _whois_lookup(domain)

        # Google Safe Browsing
        signals["google_safe_browsing"] = _google_safe_browsing(url)

        # VirusTotal
        signals["virustotal"] = _virustotal_url(url)

        # URLhaus (reuse existing module)
        signals["urlhaus"] = _urlhaus_lookup(domain)

        # GreyNoise (IP only)
        if ip:
            signals["greynoise"] = _greynoise_lookup(ip)
            signals["resolved_ip"] = ip

        # Wayback Machine
        signals["wayback"] = _wayback_first(domain)

        # â”€â”€ New v2 sources â”€â”€
        signals["rdap"] = _rdap_lookup(domain)
        signals["crtsh"] = _crtsh_lookup(domain)
        signals["spf_dmarc"] = _check_spf_dmarc(domain)
        signals["tranco"] = _tranco_lookup(domain)
        if ip:
            signals["ipinfo"] = _ipinfo_lookup(ip)
            signals["abuseipdb"] = _abuseipdb_lookup(ip)
        signals["otx"] = _otx_lookup(domain)

        risk_score = calculate_risk(signals)
        verdict = generate_verdict(risk_score, signals, url)

        return {
            "query": url,
            "type": "url",
            "domain": domain,
            "risk_score": risk_score,
            "signals": signals,
            **verdict,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }

    def verify_company(self, query: str, country: str = "PL") -> dict:
        """Verify a company in public registries."""
        signals = {}
        country = country.upper()

        if country == "PL":
            krs = _krs_lookup(query)
            ceidg = _ceidg_lookup(query)
            # Use whichever found results
            if krs.get("found"):
                signals["company"] = krs
            elif ceidg.get("found"):
                signals["company"] = ceidg
            else:
                signals["company"] = {"found": False, "registry": "KRS+CEIDG", "krs": krs, "ceidg": ceidg}
        elif country == "UK":
            signals["company"] = _companies_house_lookup(query)
        else:
            signals["company"] = {"found": False, "registry": "unsupported_country"}

        # If company has a website, check the domain too
        company = signals.get("company", {})
        company_name = company.get("name", query)

        risk_score = calculate_risk(signals)
        verdict = generate_verdict(risk_score, signals, query)

        return {
            "query": query,
            "type": "company",
            "country": country,
            "risk_score": risk_score,
            "signals": signals,
            **verdict,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }

    def verify_email(self, email: str) -> dict:
        """Verify an email address for fraud signals."""
        signals = {}

        # Extract domain
        parts = email.split("@")
        if len(parts) != 2:
            return {
                "query": email, "type": "email", "risk_score": 80,
                "verdict": "OSZUSTWO", "summary": "NieprawidÅ‚owy format adresu email.",
                "narrative": "Podany adres email ma nieprawidÅ‚owy format â€” brakuje znaku @ lub domeny. PrawidÅ‚owy email wyglÄ…da tak: nazwa@domena.pl. Nie mogliÅ›my przeprowadziÄ‡ dalszej analizy.",
                "red_flags": ["NieprawidÅ‚owy format email"],
                "trust_factors": [], "signal_explanations": [],
                "problems": [{"title": "NieprawidÅ‚owy format", "what_found": "Adres email nie zawiera znaku @ z domenÄ….", "what_means": "To nie jest prawdziwy adres email.", "real_risk": "Nie moÅ¼na zweryfikowaÄ‡ nadawcy."}],
                "positives": [],
                "action": "SprawdÅº poprawnoÅ›Ä‡ adresu email i sprÃ³buj ponownie.",
                "immediate_actions": ["SprawdÅº poprawnoÅ›Ä‡ adresu email i sprÃ³buj ponownie"],
                "if_paid_already": [],
                "report_to": [],
                "educational_tips": [{"icon": "ğŸ“§", "title": "Format email", "text": "PrawidÅ‚owy adres email zawsze ma format: nazwa@domena.pl", "example": "jan.kowalski@gmail.com â€” to poprawny adres."}],
                "recommendation": "Podaj poprawny adres email.",
                "signals": {}, "timestamp": datetime.now(timezone.utc).isoformat(),
            }

        domain = parts[1].lower()

        # Disposable email check
        disposable_domains = _load_disposable_domains()
        signals["disposable_email"] = domain in disposable_domains

        # MX records
        signals["mx"] = _check_mx(domain)

        # Domain WHOIS
        signals["whois"] = _whois_lookup(domain)

        # URLhaus for domain
        signals["urlhaus"] = _urlhaus_lookup(domain)

        # SPF/DMARC for email domain
        signals["spf_dmarc"] = _check_spf_dmarc(domain)

        risk_score = calculate_risk(signals)

        # Safe email domain override
        if domain in SAFE_EMAIL_DOMAINS:
            risk_score = min(risk_score, 15)

        verdict = generate_verdict(risk_score, signals, email)

        # Inject trust factor for safe email domains
        if domain in SAFE_EMAIL_DOMAINS:
            verdict["verdict"] = "BEZPIECZNE"
            tf = verdict.get("trust_factors", [])
            if isinstance(tf, list):
                tf.insert(0, "Znany bezpieczny dostawca poczty")
                verdict["trust_factors"] = tf

        return {
            "query": email,
            "type": "email",
            "domain": domain,
            "risk_score": risk_score,
            "signals": signals,
            **verdict,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }


def detect_query_type(query: str) -> str:
    """Auto-detect query type: url, email, or company."""
    q = query.strip()
    if "@" in q:
        return "email"
    if q.startswith("http://") or q.startswith("https://"):
        return "url"
    if "." in q and not " " in q:
        return "url"
    return "company"
