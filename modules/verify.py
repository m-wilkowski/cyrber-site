"""CYRBER VERIFY ‚Äî fraud & scam verification for URLs, companies, and emails.

Aggregates signals from multiple OSINT sources (WHOIS, Google Safe Browsing,
VirusTotal, URLhaus, GreyNoise, Wayback Machine, KRS/CEIDG, Companies House,
MX records, disposable-email lists) and produces a risk score + AI verdict.
"""

import json
import logging
import os
import re
import socket
import time
from datetime import datetime, timezone
from urllib.parse import urlparse

import requests

log = logging.getLogger("cyrber.verify")

REQUEST_TIMEOUT = 15

# ‚îÄ‚îÄ ENV keys ‚îÄ‚îÄ
GOOGLE_SAFE_BROWSING_KEY = os.getenv("GOOGLE_SAFE_BROWSING_KEY", "")
VIRUSTOTAL_KEY = os.getenv("VIRUSTOTAL_API_KEY", "") or os.getenv("VIRUSTOTAL_KEY", "")
COMPANIES_HOUSE_KEY = os.getenv("COMPANIES_HOUSE_KEY", "")
IPINFO_TOKEN = os.getenv("IPINFO_TOKEN", "")
ABUSEIPDB_API_KEY = os.getenv("ABUSEIPDB_API_KEY", "")
OTX_API_KEY = os.getenv("OTX_API_KEY", "")

# ‚îÄ‚îÄ Disposable email cache ‚îÄ‚îÄ
_DISPOSABLE_DOMAINS: set[str] | None = None
_DISPOSABLE_URL = "https://raw.githubusercontent.com/disposable-email-domains/disposable-email-domains/master/disposable_email_blocklist.conf"


def _load_disposable_domains() -> set[str]:
    """Load disposable email domain list (cached in memory)."""
    global _DISPOSABLE_DOMAINS
    if _DISPOSABLE_DOMAINS is not None:
        return _DISPOSABLE_DOMAINS
    try:
        resp = requests.get(_DISPOSABLE_URL, timeout=REQUEST_TIMEOUT)
        resp.raise_for_status()
        _DISPOSABLE_DOMAINS = {
            line.strip().lower()
            for line in resp.text.splitlines()
            if line.strip() and not line.startswith("#")
        }
        log.info(f"Loaded {len(_DISPOSABLE_DOMAINS)} disposable email domains")
    except Exception as exc:
        log.warning(f"Failed to load disposable domains: {exc}")
        _DISPOSABLE_DOMAINS = set()
    return _DISPOSABLE_DOMAINS


def _resolve_domain_ip(domain: str) -> str | None:
    """Resolve domain to IP address."""
    try:
        return socket.gethostbyname(domain)
    except socket.gaierror:
        return None


def _urlhaus_lookup(host: str) -> dict:
    """Wrapper around intelligence_sync.sync_urlhaus for testability."""
    try:
        from modules.intelligence_sync import sync_urlhaus
        return sync_urlhaus(host) or {"urls_count": 0, "blacklisted": False}
    except Exception:
        return {"urls_count": 0, "blacklisted": False}


def _greynoise_lookup(ip: str) -> dict:
    """Wrapper around intelligence_sync.sync_greynoise for testability."""
    try:
        from modules.intelligence_sync import sync_greynoise
        return sync_greynoise(ip) or {"classification": "unknown"}
    except Exception:
        return {"classification": "unknown"}


def _extract_domain(url_or_host: str) -> str:
    """Extract domain from URL or hostname."""
    if "://" in url_or_host:
        parsed = urlparse(url_or_host)
        return parsed.hostname or url_or_host
    return url_or_host.split("/")[0].split(":")[0]


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  WHOIS LOOKUP
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _whois_lookup(domain: str) -> dict:
    """Perform WHOIS lookup and return registration info."""
    try:
        import whois
        w = whois.whois(domain)
        creation = w.creation_date
        if isinstance(creation, list):
            creation = creation[0]

        expiration = w.expiration_date
        if isinstance(expiration, list):
            expiration = expiration[0]

        registrar = w.registrar or ""
        org = w.org or ""
        country = w.country or ""

        age_days = None
        if creation:
            if isinstance(creation, datetime):
                age_days = (datetime.now() - creation).days
            creation = str(creation)

        if expiration and isinstance(expiration, datetime):
            expiration = str(expiration)

        return {
            "domain": domain,
            "registrar": registrar,
            "org": org,
            "country": country,
            "creation_date": creation,
            "expiration_date": str(expiration) if expiration else None,
            "age_days": age_days,
            "available": False,
        }
    except Exception as exc:
        log.warning(f"WHOIS lookup failed for {domain}: {exc}")
        return {"domain": domain, "error": str(exc), "age_days": None, "available": True}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  GOOGLE SAFE BROWSING
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _google_safe_browsing(url: str) -> dict:
    """Check URL against Google Safe Browsing API."""
    if not GOOGLE_SAFE_BROWSING_KEY:
        return {"available": False, "reason": "no_api_key"}
    try:
        resp = requests.post(
            f"https://safebrowsing.googleapis.com/v4/threatMatches:find?key={GOOGLE_SAFE_BROWSING_KEY}",
            json={
                "client": {"clientId": "cyrber", "clientVersion": "0.3.0"},
                "threatInfo": {
                    "threatTypes": ["MALWARE", "SOCIAL_ENGINEERING", "UNWANTED_SOFTWARE", "POTENTIALLY_HARMFUL_APPLICATION"],
                    "platformTypes": ["ANY_PLATFORM"],
                    "threatEntryTypes": ["URL"],
                    "threatEntries": [{"url": url}],
                },
            },
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        data = resp.json()
        matches = data.get("matches", [])
        return {
            "available": True,
            "flagged": len(matches) > 0,
            "threats": [m.get("threatType", "") for m in matches],
        }
    except Exception as exc:
        log.warning(f"Google Safe Browsing failed: {exc}")
        return {"available": False, "error": str(exc)}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  VIRUSTOTAL
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _virustotal_url(url: str) -> dict:
    """Check URL against VirusTotal API."""
    if not VIRUSTOTAL_KEY:
        return {"available": False, "reason": "no_api_key"}
    try:
        import base64
        url_id = base64.urlsafe_b64encode(url.encode()).decode().rstrip("=")
        resp = requests.get(
            f"https://www.virustotal.com/api/v3/urls/{url_id}",
            headers={"x-apikey": VIRUSTOTAL_KEY},
            timeout=REQUEST_TIMEOUT,
        )
        if resp.status_code == 404:
            return {"available": True, "found": False, "positives": 0, "total": 0}
        resp.raise_for_status()
        data = resp.json().get("data", {}).get("attributes", {})
        stats = data.get("last_analysis_stats", {})
        positives = stats.get("malicious", 0) + stats.get("suspicious", 0)
        total = sum(stats.values()) if stats else 0
        return {
            "available": True,
            "found": True,
            "positives": positives,
            "total": total,
            "reputation": data.get("reputation", 0),
            "categories": data.get("categories", {}),
        }
    except Exception as exc:
        log.warning(f"VirusTotal URL check failed: {exc}")
        return {"available": False, "error": str(exc)}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  WAYBACK MACHINE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _wayback_first(domain: str) -> dict:
    """Check first archive date via Wayback Machine CDX API."""
    try:
        resp = requests.get(
            f"https://web.archive.org/cdx/search/cdx?url={domain}&limit=1&output=json&fl=timestamp",
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        data = resp.json()
        if len(data) > 1:
            ts = data[1][0]  # first row after header
            first_date = datetime.strptime(ts[:8], "%Y%m%d")
            age_days = (datetime.now() - first_date).days
            return {"available": True, "first_archive": str(first_date.date()), "archive_age_days": age_days}
        return {"available": True, "first_archive": None, "archive_age_days": None}
    except Exception as exc:
        log.warning(f"Wayback Machine lookup failed for {domain}: {exc}")
        return {"available": False, "error": str(exc)}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MX RECORDS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _check_mx(domain: str) -> dict:
    """Check MX records for a domain."""
    try:
        import dns.resolver
        answers = dns.resolver.resolve(domain, "MX")
        records = [{"host": str(r.exchange).rstrip("."), "priority": r.preference} for r in answers]
        return {"has_mx": True, "records": records}
    except Exception:
        return {"has_mx": False, "records": []}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  RDAP (Registration Data Access Protocol)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _rdap_lookup(domain: str) -> dict:
    """Perform RDAP lookup for domain registration data."""
    try:
        resp = requests.get(f"https://rdap.org/domain/{domain}", timeout=REQUEST_TIMEOUT)
        if resp.status_code == 404:
            return {"available": False, "error": "not_found"}
        resp.raise_for_status()
        data = resp.json()

        registrar = ""
        registration = None
        expiry = None
        status = []

        # Extract registrar from entities
        for entity in data.get("entities", []):
            if "registrar" in entity.get("roles", []):
                vcard = entity.get("vcardArray", [None, []])[1] if entity.get("vcardArray") else []
                for item in vcard:
                    if isinstance(item, list) and len(item) >= 4 and item[0] == "fn":
                        registrar = item[3]

        # Extract dates from events
        for event in data.get("events", []):
            action = event.get("eventAction", "")
            date = event.get("eventDate", "")
            if action == "registration":
                registration = date
            elif action == "expiration":
                expiry = date

        status = data.get("status", [])

        return {
            "available": True,
            "registration": registration,
            "expiry": expiry,
            "registrar": registrar,
            "status": status,
        }
    except Exception as exc:
        log.warning(f"RDAP lookup failed for {domain}: {exc}")
        return {"available": False, "error": str(exc)}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  CRT.SH (Certificate Transparency)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _crtsh_lookup(domain: str) -> dict:
    """Check oldest certificate via crt.sh."""
    try:
        resp = requests.get(
            f"https://crt.sh/?q={domain}&output=json&limit=1",
            timeout=REQUEST_TIMEOUT,
            headers={"Accept": "application/json"},
        )
        if resp.status_code == 404 or not resp.text.strip():
            return {"available": True, "cert_age_days": None}
        resp.raise_for_status()
        data = resp.json()
        if not data:
            return {"available": True, "cert_age_days": None}
        oldest = data[-1] if isinstance(data, list) else data
        not_before = oldest.get("not_before") or oldest.get("entry_timestamp", "")
        if not_before:
            cert_date = datetime.strptime(not_before[:10], "%Y-%m-%d")
            cert_age_days = (datetime.now() - cert_date).days
            return {"available": True, "cert_age_days": cert_age_days, "issuer": oldest.get("issuer_name", "")}
        return {"available": True, "cert_age_days": None}
    except Exception as exc:
        log.warning(f"crt.sh lookup failed for {domain}: {exc}")
        return {"available": False, "error": str(exc)}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  SPF / DMARC DNS check
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _check_spf_dmarc(domain: str) -> dict:
    """Check SPF and DMARC DNS TXT records."""
    result = {"has_spf": False, "has_dmarc": False}
    try:
        import dns.resolver
        try:
            answers = dns.resolver.resolve(domain, "TXT")
            for rdata in answers:
                txt = str(rdata).strip('"')
                if txt.startswith("v=spf1"):
                    result["has_spf"] = True
        except Exception:
            pass
        try:
            answers = dns.resolver.resolve(f"_dmarc.{domain}", "TXT")
            for rdata in answers:
                txt = str(rdata).strip('"')
                if txt.startswith("v=DMARC1"):
                    result["has_dmarc"] = True
        except Exception:
            pass
    except Exception as exc:
        log.warning(f"SPF/DMARC check failed for {domain}: {exc}")
    return result


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  IPINFO
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _ipinfo_lookup(ip: str) -> dict:
    """Lookup IP info via ipinfo.io."""
    try:
        headers = {}
        url = f"https://ipinfo.io/{ip}/json"
        if IPINFO_TOKEN:
            headers["Authorization"] = f"Bearer {IPINFO_TOKEN}"
        resp = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        resp.raise_for_status()
        data = resp.json()
        return {
            "available": True,
            "org": data.get("org", ""),
            "country": data.get("country", ""),
            "city": data.get("city", ""),
            "hosting": data.get("hosting", False),
        }
    except Exception as exc:
        log.warning(f"IPinfo lookup failed for {ip}: {exc}")
        return {"available": False, "error": str(exc)}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  ABUSEIPDB
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _abuseipdb_lookup(ip: str) -> dict:
    """Check IP against AbuseIPDB."""
    if not ABUSEIPDB_API_KEY:
        return {"available": False, "reason": "no_api_key"}
    try:
        resp = requests.get(
            "https://api.abuseipdb.com/api/v2/check",
            headers={"Key": ABUSEIPDB_API_KEY, "Accept": "application/json"},
            params={"ipAddress": ip, "maxAgeInDays": 90},
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        d = resp.json().get("data", {})
        return {
            "available": True,
            "abuseConfidenceScore": d.get("abuseConfidenceScore", 0),
            "totalReports": d.get("totalReports", 0),
            "isWhitelisted": d.get("isWhitelisted", False),
            "countryCode": d.get("countryCode", ""),
        }
    except Exception as exc:
        log.warning(f"AbuseIPDB lookup failed for {ip}: {exc}")
        return {"available": False, "error": str(exc)}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  OTX (AlienVault Open Threat Exchange)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _otx_lookup(domain: str) -> dict:
    """Check domain in AlienVault OTX."""
    try:
        headers = {"Accept": "application/json"}
        if OTX_API_KEY:
            headers["X-OTX-API-KEY"] = OTX_API_KEY
        resp = requests.get(
            f"https://otx.alienvault.com/api/v1/indicators/domain/{domain}/general",
            headers=headers,
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        data = resp.json()
        pulse_count = data.get("pulse_info", {}).get("count", 0)
        validation = data.get("validation", [])
        return {
            "available": True,
            "pulse_count": pulse_count,
            "validation": validation,
        }
    except Exception as exc:
        log.warning(f"OTX lookup failed for {domain}: {exc}")
        return {"available": False, "error": str(exc)}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  TRANCO (Top Sites Ranking)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _tranco_lookup(domain: str) -> dict:
    """Check domain ranking in Tranco top list."""
    try:
        resp = requests.get(
            f"https://tranco-list.eu/api/ranks/domain/{domain}",
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        data = resp.json()
        # Tranco returns ranks array
        ranks = data.get("ranks", [])
        rank = ranks[0].get("rank") if ranks else None
        return {"available": True, "rank": rank}
    except Exception as exc:
        log.warning(f"Tranco lookup failed for {domain}: {exc}")
        return {"available": False, "rank": None}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  COMPANY REGISTRIES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _krs_lookup(nip_or_name: str) -> dict:
    """Check Polish KRS registry."""
    # Detect if it's a NIP (10 digits) or name
    clean = re.sub(r"[\s-]", "", nip_or_name)
    if re.match(r"^\d{10}$", clean):
        url = f"https://api-krs.ms.gov.pl/api/krs/OdpisAktualny/{clean}?rejestr=P&format=json"
    else:
        url = f"https://api-krs.ms.gov.pl/api/krs/OdpisAktualny/{nip_or_name}?rejestr=P&format=json"

    try:
        resp = requests.get(url, timeout=REQUEST_TIMEOUT)
        if resp.status_code == 404:
            return {"found": False, "registry": "KRS"}
        resp.raise_for_status()
        data = resp.json()
        dane = data.get("odpis", {}).get("dane", {})
        return {
            "found": True,
            "registry": "KRS",
            "name": dane.get("nazwa", ""),
            "krs": dane.get("numerKRS", ""),
            "nip": dane.get("nip", ""),
            "regon": dane.get("regon", ""),
            "address": dane.get("adres", ""),
            "registration_date": dane.get("dataRejestracjiWKRS", ""),
            "status": "active",
        }
    except Exception as exc:
        log.warning(f"KRS lookup failed: {exc}")
        return {"found": False, "registry": "KRS", "error": str(exc)}


def _ceidg_lookup(nip_or_name: str) -> dict:
    """Check Polish CEIDG registry (sole proprietors)."""
    clean = re.sub(r"[\s-]", "", nip_or_name)
    if re.match(r"^\d{10}$", clean):
        url = f"https://dane.biznes.gov.pl/api/ceidg/v2/firma?nip={clean}"
    else:
        url = f"https://dane.biznes.gov.pl/api/ceidg/v2/firma?nazwa={nip_or_name}"

    try:
        resp = requests.get(url, timeout=REQUEST_TIMEOUT)
        if resp.status_code == 404:
            return {"found": False, "registry": "CEIDG"}
        resp.raise_for_status()
        data = resp.json()
        firmy = data.get("firmy", [])
        if not firmy:
            return {"found": False, "registry": "CEIDG"}
        f = firmy[0]
        return {
            "found": True,
            "registry": "CEIDG",
            "name": f.get("nazwa", ""),
            "nip": f.get("wlasciciel", {}).get("nip", ""),
            "status": f.get("status", ""),
            "start_date": f.get("dataRozpoczeciaDzialalnosci", ""),
            "address": f.get("adresDzialalnosci", {}).get("adres", ""),
        }
    except Exception as exc:
        log.warning(f"CEIDG lookup failed: {exc}")
        return {"found": False, "registry": "CEIDG", "error": str(exc)}


def _companies_house_lookup(query: str) -> dict:
    """Check UK Companies House registry."""
    if not COMPANIES_HOUSE_KEY:
        return {"found": False, "registry": "Companies House", "reason": "no_api_key"}
    try:
        resp = requests.get(
            f"https://api.company-information.service.gov.uk/search/companies?q={query}",
            auth=(COMPANIES_HOUSE_KEY, ""),
            timeout=REQUEST_TIMEOUT,
        )
        resp.raise_for_status()
        data = resp.json()
        items = data.get("items", [])
        if not items:
            return {"found": False, "registry": "Companies House"}
        c = items[0]
        return {
            "found": True,
            "registry": "Companies House",
            "name": c.get("title", ""),
            "company_number": c.get("company_number", ""),
            "status": c.get("company_status", ""),
            "date_of_creation": c.get("date_of_creation", ""),
            "address": c.get("address_snippet", ""),
            "company_type": c.get("company_type", ""),
        }
    except Exception as exc:
        log.warning(f"Companies House lookup failed: {exc}")
        return {"found": False, "registry": "Companies House", "error": str(exc)}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  RISK SCORING
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def calculate_risk(signals: dict) -> int:
    """Calculate risk score (0-100) from aggregated signals ‚Äî bidirectional scoring.

    Positive factors increase risk, negative factors (trust signals) decrease it.
    Floor: 0, Cap: 100.
    Thresholds: <20 BEZPIECZNE, 20-50 PODEJRZANE, >50 OSZUSTWO.
    """
    score = 0

    # ‚îÄ‚îÄ INCREASING FACTORS ‚îÄ‚îÄ

    # WHOIS age
    whois_data = signals.get("whois", {})
    age = whois_data.get("age_days")
    if age is not None:
        if age < 90:
            score += 40
        elif age < 365:
            score += 20

    # Domain looks available / unregistered
    if whois_data.get("available"):
        score += 30

    # Google Safe Browsing
    gsb = signals.get("google_safe_browsing", {})
    if gsb.get("flagged"):
        score += 70

    # VirusTotal
    vt = signals.get("virustotal", {})
    if vt.get("positives", 0) >= 5:
        score += 60
    elif vt.get("positives", 0) >= 2:
        score += 30

    # URLhaus
    urlhaus = signals.get("urlhaus", {})
    if urlhaus.get("blacklisted"):
        score += 50

    # GreyNoise
    gn = signals.get("greynoise", {})
    if gn.get("classification") == "malicious":
        score += 30

    # Company registry ‚Äî not found
    company = signals.get("company", {})
    if company and not company.get("found", True):
        score += 60

    # Disposable email
    if signals.get("disposable_email"):
        score += 50

    # No MX records
    mx = signals.get("mx", {})
    if mx and not mx.get("has_mx", True):
        score += 30

    # Wayback Machine ‚Äî very new site
    wb = signals.get("wayback", {})
    archive_age = wb.get("archive_age_days")
    if archive_age is not None and archive_age < 180:
        score += 25

    # AbuseIPDB high score
    abuse = signals.get("abuseipdb", {})
    abuse_score = abuse.get("abuseConfidenceScore", 0)
    if abuse_score > 50:
        score += 40
    elif abuse_score > 20:
        score += 20

    # OTX pulses
    otx = signals.get("otx", {})
    otx_pulses = otx.get("pulse_count", 0)
    if otx_pulses > 5:
        score += 40
    elif otx_pulses > 0:
        score += 20

    # IPinfo ‚Äî high-risk countries
    ipinfo = signals.get("ipinfo", {})
    ipinfo_country = (ipinfo.get("country") or "").upper()
    if ipinfo_country in ("UA", "RU", "KP", "IR", "CN"):
        score += 25

    # SPF/DMARC ‚Äî both missing
    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc and not spf_dmarc.get("has_spf") and not spf_dmarc.get("has_dmarc"):
        score += 15

    # crt.sh ‚Äî very new cert
    crtsh = signals.get("crtsh", {})
    cert_age = crtsh.get("cert_age_days")
    if cert_age is not None and cert_age < 30:
        score += 25

    # No Tranco rank (not in top 1M)
    tranco = signals.get("tranco", {})
    if tranco.get("available") and tranco.get("rank") is None:
        score += 10

    # ‚îÄ‚îÄ DECREASING FACTORS (trust signals) ‚îÄ‚îÄ

    # Tranco ranking
    tranco_rank = tranco.get("rank")
    if tranco_rank is not None:
        if tranco_rank <= 10000:
            score -= 50
        elif tranco_rank <= 100000:
            score -= 30
        elif tranco_rank <= 1000000:
            score -= 15

    # AbuseIPDB whitelisted
    if abuse.get("isWhitelisted"):
        score -= 30

    # OTX validation non-empty (domain validated / analyzed)
    if otx.get("validation") and len(otx["validation"]) > 0:
        score -= 20

    # Domain age ‚Äî long-standing
    if age is not None:
        if age > 3650:  # >10 years
            score -= 30
        elif age > 1825:  # >5 years
            score -= 20

    # crt.sh ‚Äî old cert (>2 years)
    if cert_age is not None and cert_age > 730:
        score -= 20

    # SPF + DMARC both present
    if spf_dmarc.get("has_spf") and spf_dmarc.get("has_dmarc"):
        score -= 10

    # Company confirmed in registry
    if company and company.get("found"):
        score -= 40

    return max(0, min(100, score))


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  AI VERDICT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _extract_problems(signals: dict) -> list[dict]:
    """Convert red flags into structured problem cards with what_found/what_means/real_risk."""
    problems = []

    whois = signals.get("whois", {})
    age = whois.get("age_days")
    if age is not None and age < 90:
        problems.append({
            "title": "Bardzo nowa domena",
            "what_found": f"Domena zosta≈Ça zarejestrowana zaledwie {age} dni temu.",
            "what_means": "Oszu≈õci zak≈ÇadajƒÖ nowe strony tu≈º przed atakiem i porzucajƒÖ je po kilku tygodniach. Legalne firmy majƒÖ domeny od lat.",
            "real_risk": "Strona mo≈ºe zniknƒÖƒá razem z Twoimi pieniƒôdzmi.",
        })
    elif age is not None and age < 365:
        problems.append({
            "title": "Stosunkowo nowa domena",
            "what_found": f"Domena istnieje od {age} dni (mniej ni≈º rok).",
            "what_means": "Nowe domeny nie muszƒÖ byƒá z≈Ço≈õliwe, ale warto zachowaƒá czujno≈õƒá ‚Äî wiƒôkszo≈õƒá oszustw odbywa siƒô na domenach m≈Çodszych ni≈º rok.",
            "real_risk": "Podwy≈ºszone ryzyko ‚Äî zweryfikuj firmƒô innymi kana≈Çami.",
        })

    gsb = signals.get("google_safe_browsing", {})
    if gsb.get("flagged"):
        threats = ", ".join(gsb.get("threats", []))
        problems.append({
            "title": "Google ostrzega przed tƒÖ stronƒÖ",
            "what_found": f"Google Safe Browsing aktywnie blokuje tƒô stronƒô. Zagro≈ºenia: {threats}.",
            "what_means": "Google przeskanowa≈Ç miliardy stron i oznaczy≈Ç tƒô jako niebezpiecznƒÖ. Twoja przeglƒÖdarka powinna pokazaƒá ostrze≈ºenie.",
            "real_risk": "Wej≈õcie na tƒô stronƒô mo≈ºe zainstalowaƒá z≈Ço≈õliwe oprogramowanie lub wykra≈õƒá Twoje dane.",
        })

    vt = signals.get("virustotal", {})
    pos = vt.get("positives", 0)
    if pos >= 5:
        problems.append({
            "title": "Antywirusy oznaczajƒÖ jako z≈Ço≈õliwe",
            "what_found": f"{pos} z {vt.get('total', 0)} silnik√≥w antywirusowych oznaczy≈Ço ten URL.",
            "what_means": "To jak gdyby kilkudziesiƒôciu lekarzy zbada≈Ço pacjenta i wiƒôkszo≈õƒá powiedzia≈Ça, ≈ºe jest chory. Je≈õli wiele antywirus√≥w siƒô zgadza ‚Äî to powa≈ºny sygna≈Ç.",
            "real_risk": "Mo≈ºesz straciƒá pieniƒÖdze lub dane osobowe.",
        })
    elif pos >= 2:
        problems.append({
            "title": "Kilka antywirus√≥w ma zastrze≈ºenia",
            "what_found": f"{pos} z {vt.get('total', 0)} silnik√≥w oznaczy≈Ço ten URL.",
            "what_means": "Nie jest to jednoznaczne, ale kilka niezale≈ºnych system√≥w zabezpiecze≈Ñ wykry≈Ço potencjalne zagro≈ºenie.",
            "real_risk": "Zachowaj ostro≈ºno≈õƒá ‚Äî nie podawaj danych osobowych.",
        })

    urlhaus = signals.get("urlhaus", {})
    if urlhaus.get("blacklisted"):
        problems.append({
            "title": "Strona na czarnej li≈õcie",
            "what_found": "URLhaus (baza z≈Ço≈õliwych stron) ma tƒô domenƒô na czarnej li≈õcie.",
            "what_means": "Ta strona by≈Ça wcze≈õniej wykorzystywana do rozprzestrzeniania z≈Ço≈õliwego oprogramowania lub phishingu.",
            "real_risk": "Tw√≥j komputer mo≈ºe zostaƒá zainfekowany wirusem.",
        })

    gn = signals.get("greynoise", {})
    if gn.get("classification") == "malicious":
        problems.append({
            "title": "IP oznaczone jako z≈Ço≈õliwe",
            "what_found": "GreyNoise klasyfikuje adres IP serwera jako z≈Ço≈õliwy.",
            "what_means": "Serwer, na kt√≥rym stoi ta strona, jest znany z podejrzanej aktywno≈õci w internecie.",
            "real_risk": "Strona mo≈ºe byƒá czƒô≈õciƒÖ wiƒôkszej sieci oszustw.",
        })

    company = signals.get("company", {})
    if company and not company.get("found", True):
        problems.append({
            "title": "Firma nie istnieje w rejestrze",
            "what_found": "Nie znale≈∫li≈õmy tej firmy w oficjalnym rejestrze KRS ani CEIDG.",
            "what_means": "Ka≈ºda legalna polska firma musi byƒá zarejestrowana. Je≈õli jej nie ma w rejestrze ‚Äî albo podaje fa≈ÇszywƒÖ nazwƒô, albo dzia≈Ça nielegalnie.",
            "real_risk": "Nie masz ≈ºadnej ochrony prawnej je≈õli firma Ciƒô oszuka.",
        })

    if signals.get("disposable_email"):
        problems.append({
            "title": "Jednorazowy adres email",
            "what_found": "Domena emailowa nale≈ºy do serwisu jednorazowych adres√≥w.",
            "what_means": "Osoba u≈ºywa tymczasowego emaila, kt√≥ry za chwilƒô przestanie istnieƒá. Legalne firmy nie u≈ºywajƒÖ takich adres√≥w.",
            "real_risk": "Nie bƒôdziesz w stanie skontaktowaƒá siƒô z nadawcƒÖ.",
        })

    mx = signals.get("mx", {})
    if mx and not mx.get("has_mx", True):
        problems.append({
            "title": "Domena nie obs≈Çuguje poczty",
            "what_found": "Brak rekord√≥w MX ‚Äî ta domena nie mo≈ºe wysy≈Çaƒá ani odbieraƒá emaili.",
            "what_means": "Je≈õli firma twierdzi, ≈ºe kontakt jest przez email na tej domenie ‚Äî k≈Çamie.",
            "real_risk": "Odpowiedzi na emaile nie dotrƒÖ do nikogo.",
        })

    abuse = signals.get("abuseipdb", {})
    if abuse.get("abuseConfidenceScore", 0) > 20:
        problems.append({
            "title": "IP zg≈Çaszane za nadu≈ºycia",
            "what_found": f"AbuseIPDB: {abuse['abuseConfidenceScore']}% pewno≈õci nadu≈ºyƒá, {abuse.get('totalReports', 0)} zg≈Çosze≈Ñ.",
            "what_means": "Inni internauci zg≈Çaszali problemy z tym adresem IP ‚Äî spam, ataki, oszustwa.",
            "real_risk": "Serwer ma z≈ÇƒÖ reputacjƒô w spo≈Çeczno≈õci bezpiecze≈Ñstwa.",
        })

    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc and not spf_dmarc.get("has_spf") and not spf_dmarc.get("has_dmarc"):
        problems.append({
            "title": "Brak ochrony przed podszywaniem",
            "what_found": "Domena nie ma zabezpiecze≈Ñ SPF ani DMARC.",
            "what_means": "Ktokolwiek mo≈ºe wysy≈Çaƒá emaile udajƒÖc, ≈ºe jest z tej domeny. To jak gdyby firma nie mia≈Ça pieczƒÖtki.",
            "real_risk": "Mo≈ºesz dostaƒá fa≈Çszywy email wyglƒÖdajƒÖcy jak od tej firmy.",
        })

    crtsh = signals.get("crtsh", {})
    if crtsh.get("cert_age_days") is not None and crtsh["cert_age_days"] < 30:
        problems.append({
            "title": "Bardzo nowy certyfikat SSL",
            "what_found": f"Certyfikat SSL wystawiony {crtsh['cert_age_days']} dni temu.",
            "what_means": "Oszu≈õci uzyskujƒÖ certyfikaty SSL tu≈º przed atakiem, ≈ºeby strona wyglƒÖda≈Ça na bezpiecznƒÖ (k≈Ç√≥dka w przeglƒÖdarce).",
            "real_risk": "K≈Ç√≥dka w przeglƒÖdarce NIE gwarantuje bezpiecze≈Ñstwa.",
        })

    otx = signals.get("otx", {})
    if otx.get("pulse_count", 0) > 0:
        problems.append({
            "title": "Widoczna w raportach zagro≈ºe≈Ñ",
            "what_found": f"OTX AlienVault: {otx['pulse_count']} raport√≥w threat intelligence.",
            "what_means": "Eksperci ds. bezpiecze≈Ñstwa analizowali tƒô domenƒô i powiƒÖzali jƒÖ z zagro≈ºeniami.",
            "real_risk": "Domena jest znana w ≈õwiecie cyberbezpiecze≈Ñstwa jako podejrzana.",
        })

    return problems


def _extract_positives(signals: dict) -> list[dict]:
    """Convert trust factors into structured positive cards with what_found/what_means."""
    positives = []

    tranco = signals.get("tranco", {})
    rank = tranco.get("rank")
    if rank is not None:
        if rank <= 10000:
            positives.append({
                "title": "Popularna strona",
                "what_found": f"Domena jest na pozycji #{rank} w rankingu Tranco (top 10K).",
                "what_means": "To jedna z najpopularniejszych stron w internecie ‚Äî miliony ludzi z niej korzystajƒÖ.",
            })
        elif rank <= 100000:
            positives.append({
                "title": "Znana strona",
                "what_found": f"Domena jest na pozycji #{rank} w rankingu Tranco.",
                "what_means": "Strona ma spory ruch ‚Äî to dobry znak, bo oszu≈õci rzadko osiƒÖgajƒÖ takƒÖ popularno≈õƒá.",
            })

    whois = signals.get("whois", {})
    age = whois.get("age_days")
    if age is not None and age > 3650:
        positives.append({
            "title": "Domena od wielu lat",
            "what_found": f"Domena istnieje od {age // 365} lat.",
            "what_means": "D≈Çugo dzia≈ÇajƒÖce domeny to dobry znak ‚Äî oszu≈õci porzucajƒÖ strony po kilku miesiƒÖcach.",
        })
    elif age is not None and age > 1825:
        positives.append({
            "title": "Ugruntowana domena",
            "what_found": f"Domena istnieje od {age // 365} lat.",
            "what_means": "Kilka lat dzia≈Çalno≈õci buduje zaufanie.",
        })

    abuse = signals.get("abuseipdb", {})
    if abuse.get("isWhitelisted"):
        positives.append({
            "title": "IP na bia≈Çej li≈õcie",
            "what_found": "AbuseIPDB uznaje ten adres IP za zaufany.",
            "what_means": "Serwer jest oficjalnie uznawany za bezpieczny przez spo≈Çeczno≈õƒá bezpiecze≈Ñstwa.",
        })

    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc.get("has_spf") and spf_dmarc.get("has_dmarc"):
        positives.append({
            "title": "Ochrona przed spoofingiem",
            "what_found": "Domena ma skonfigurowane zabezpieczenia SPF + DMARC.",
            "what_means": "Firma dba o bezpiecze≈Ñstwo emaili ‚Äî nikt nie mo≈ºe siƒô pod niƒÖ podszywaƒá.",
        })

    company = signals.get("company", {})
    if company and company.get("found"):
        registry = company.get("registry", "rejestr")
        positives.append({
            "title": "Firma w oficjalnym rejestrze",
            "what_found": f"Firma potwierdzona w {registry}.",
            "what_means": "Firma jest oficjalnie zarejestrowana, co oznacza ≈ºe podlega polskiemu prawu i mo≈ºna jƒÖ pociƒÖgnƒÖƒá do odpowiedzialno≈õci.",
        })

    crtsh = signals.get("crtsh", {})
    cert_age = crtsh.get("cert_age_days")
    if cert_age is not None and cert_age > 730:
        positives.append({
            "title": "D≈Çugotrwa≈Çy certyfikat SSL",
            "what_found": f"Certyfikat SSL od {cert_age // 365} lat.",
            "what_means": "Strona od dawna dba o szyfrowanie ‚Äî to dobra praktyka.",
        })

    return positives


def _generate_action(risk_score: int, query: str) -> str:
    """Generate concrete action recommendation based on risk score."""
    if risk_score > 50:
        return f"Nie wchod≈∫ na {query}. Je≈õli kto≈õ przys≈Ça≈Ç Ci ten link ‚Äî zignoruj wiadomo≈õƒá. Je≈õli poda≈Çe≈õ dane, natychmiast zmie≈Ñ has≈Ça i skontaktuj siƒô z bankiem."
    elif risk_score >= 20:
        return f"Zachowaj ostro≈ºno≈õƒá. Nie podawaj danych osobowych ani finansowych na {query}. Sprawd≈∫ adres URL dok≈Çadnie ‚Äî czy to na pewno oficjalna strona?"
    else:
        return f"Strona {query} wyglƒÖda bezpiecznie. Pamiƒôtaj jednak, aby zawsze sprawdzaƒá adres URL przed podaniem danych."


def _generate_immediate_actions(risk_score: int, query: str) -> list[str]:
    """Generate numbered list of immediate actions."""
    if risk_score > 50:
        return [
            f"Nie wchod≈∫ na {query} ‚Äî zamknij kartƒô je≈õli jest otwarta",
            "Je≈õli kliknƒÖ≈Çe≈õ link ‚Äî uruchom skanowanie antywirusowe na komputerze",
            "Je≈õli poda≈Çe≈õ login/has≈Ço ‚Äî natychmiast zmie≈Ñ has≈Ço na tej i innych stronach gdzie u≈ºywasz tego samego",
            "Ostrze≈º osobƒô, kt√≥ra przys≈Ça≈Ça Ci ten link ‚Äî jej konto mog≈Ço zostaƒá przejƒôte",
        ]
    elif risk_score >= 20:
        return [
            f"Nie podawaj ≈ºadnych danych osobowych ani finansowych na {query}",
            "Sprawd≈∫ adres URL literka po literce ‚Äî czy to na pewno oficjalna strona?",
            "Poszukaj opinii o tej firmie w Google ‚Äî dopisz s≈Çowo 'oszustwo' lub 'opinie'",
            "Je≈õli chcesz co≈õ kupiƒá ‚Äî szukaj tej samej oferty na znanych portalach (Allegro, OLX)",
        ]
    else:
        return [
            "Strona wyglƒÖda bezpiecznie ‚Äî mo≈ºesz z niej korzystaƒá",
            "Mimo to zawsze sprawdzaj adres URL przed podaniem danych",
            "U≈ºywaj silnych, unikalnych hase≈Ç na ka≈ºdej stronie",
        ]


def _generate_if_paid_already(risk_score: int) -> list[str]:
    """Generate steps for when user already paid/shared data."""
    if risk_score > 50:
        return [
            "Natychmiast zadzwo≈Ñ do swojego banku i zablokuj kartƒô/konto",
            "Zmie≈Ñ has≈Ça ‚Äî zacznij od banku, potem email, potem reszta",
            "W≈ÇƒÖcz weryfikacjƒô dwuetapowƒÖ (2FA) wszƒôdzie gdzie to mo≈ºliwe",
            "Zg≈Ço≈õ sprawƒô na policjƒô i do CERT Polska (incydent.cert.pl)",
            "Monitoruj wyciƒÖgi bankowe przez najbli≈ºsze 30 dni",
        ]
    elif risk_score >= 20:
        return [
            "Sprawd≈∫ wyciƒÖg bankowy ‚Äî czy sƒÖ nieautoryzowane transakcje",
            "Zmie≈Ñ has≈Ço je≈õli poda≈Çe≈õ je na tej stronie",
            "Je≈õli poda≈Çe≈õ dane karty ‚Äî skontaktuj siƒô z bankiem",
            "Zachowaj dowody (screenshoty, emaile) na wypadek reklamacji",
        ]
    else:
        return []


def _generate_report_to(risk_score: int) -> list[dict]:
    """Generate list of institutions to report fraud to."""
    if risk_score <= 20:
        return []
    institutions = []
    if risk_score > 50:
        institutions.append({
            "institution": "CERT Polska",
            "url": "https://incydent.cert.pl",
            "description": "Zg≈Ço≈õ stronƒô phishingowƒÖ lub oszustwo internetowe. CERT doda jƒÖ do listy ostrze≈ºe≈Ñ.",
        })
        institutions.append({
            "institution": "Policja ‚Äî cyberprzestƒôpczo≈õƒá",
            "url": "https://www.policja.pl/pol/zgloszenie",
            "description": "Z≈Ç√≥≈º oficjalne zawiadomienie o przestƒôpstwie. Bƒôdziesz potrzebowaƒá screenshot√≥w i dowod√≥w wp≈Çaty.",
        })
    institutions.append({
        "institution": "UOKiK",
        "url": "https://uokik.gov.pl/kontakt",
        "description": "Zg≈Ço≈õ nieuczciwƒÖ praktykƒô handlowƒÖ. UOKiK mo≈ºe na≈Ço≈ºyƒá karƒô na firmƒô.",
    })
    institutions.append({
        "institution": "Tw√≥j bank",
        "url": "",
        "description": "Zadzwo≈Ñ na infoliniƒô banku i popro≈õ o procedurƒô chargeback (zwrot pieniƒôdzy za oszustwo).",
    })
    return institutions


def _generate_narrative(risk_score: int, signals: dict, query: str) -> str:
    """Generate a warm, educational narrative about the verification result."""
    problems = _extract_problems(signals)
    positives = _extract_positives(signals)

    if risk_score > 50:
        intro = f"Sprawdzili≈õmy {query} w {len(signals)} niezale≈ºnych bazach danych bezpiecze≈Ñstwa i mamy powa≈ºne obawy."
        detail = f" Znale≈∫li≈õmy {len(problems)} sygna≈Ç√≥w ostrzegawczych." if problems else ""
        advice = " Zdecydowanie odradzamy interakcjƒô z tƒÖ stronƒÖ ‚Äî wiele wskazuje na to, ≈ºe mo≈ºe byƒá niebezpieczna."
        outro = " Je≈õli otrzyma≈Çe≈õ ten link w wiadomo≈õci od kogo≈õ ‚Äî nie klikaj i ostrze≈º nadawcƒô, bo jego konto mog≈Ço zostaƒá przejƒôte."
    elif risk_score >= 20:
        intro = f"Sprawdzili≈õmy {query} i znale≈∫li≈õmy mieszane sygna≈Çy."
        detail = f" Z jednej strony {len(positives)} czynnik√≥w wyglƒÖda dobrze, ale {len(problems)} budzi nasze wƒÖtpliwo≈õci." if positives and problems else ""
        advice = " Nie oznacza to od razu oszustwa, ale zalecamy zachowanie czujno≈õci."
        outro = " Zanim podasz jakiekolwiek dane, upewnij siƒô ≈ºe to oficjalna strona firmy, z kt√≥rƒÖ chcesz mieƒá do czynienia."
    else:
        intro = f"Sprawdzili≈õmy {query} w naszych bazach bezpiecze≈Ñstwa i wszystko wyglƒÖda w porzƒÖdku."
        detail = f" Znale≈∫li≈õmy {len(positives)} pozytywnych sygna≈Ç√≥w zaufania." if positives else ""
        advice = " Strona ma dobre wska≈∫niki bezpiecze≈Ñstwa."
        outro = " Pamiƒôtaj jednak, ≈ºe ≈ºadna automatyczna analiza nie daje 100% pewno≈õci ‚Äî zawsze warto zachowaƒá zdrowy rozsƒÖdek."

    return intro + detail + advice + outro


def _generate_educational_tips(risk_score: int, signals: dict) -> list[dict]:
    """Generate structured educational tips based on analysis."""
    tips = []

    whois = signals.get("whois", {})
    if whois.get("age_days") is not None:
        tips.append({
            "icon": "üìÖ",
            "title": "Sprawdzaj wiek domeny",
            "text": "Legalne firmy dzia≈ÇajƒÖ od lat. Je≈õli domena ma mniej ni≈º 90 dni ‚Äî to powa≈ºny sygna≈Ç ostrzegawczy.",
            "example": "Nastƒôpnym razem wpisz nazwƒô strony na whois.domaintools.com ‚Äî zobaczysz kiedy zosta≈Ça zarejestrowana.",
        })

    spf = signals.get("spf_dmarc", {})
    if spf:
        tips.append({
            "icon": "üìß",
            "title": "SPF i DMARC chroniƒÖ przed fa≈Çszywymi emailami",
            "text": "To jak pieczƒÖtka na li≈õcie ‚Äî potwierdza, ≈ºe email naprawdƒô pochodzi z tej firmy. Bez SPF i DMARC ktokolwiek mo≈ºe udawaƒá danƒÖ firmƒô.",
            "example": "Je≈õli dostaniesz email 'z banku' ‚Äî sprawd≈∫ czy bank ma SPF/DMARC. Wiƒôkszo≈õƒá du≈ºych firm je ma.",
        })

    if signals.get("virustotal", {}).get("available"):
        tips.append({
            "icon": "üîç",
            "title": "Jak samodzielnie sprawdziƒá link?",
            "text": "Wklej podejrzany link na virustotal.com ‚Äî 70+ silnik√≥w antywirusowych sprawdzi go za darmo. Nigdy nie klikaj linku, zanim go nie zweryfikujesz.",
            "example": "Kopiuj link (prawy przycisk ‚Üí Kopiuj adres linku) i wklej na virustotal.com zamiast klikaƒá.",
        })

    if signals.get("tranco", {}):
        tips.append({
            "icon": "üìä",
            "title": "Ranking popularno≈õci stron",
            "text": "Tranco to niezale≈ºny ranking miliona najpopularniejszych stron. Je≈õli strona jest w top 10K ‚Äî prawie na pewno jest legalna.",
            "example": "Google.com jest w top 10, Allegro.pl w top 1000. Nowa strona z ofertƒÖ 'za dobrƒÖ ≈ºeby by≈Ça prawdziwa' raczej nie bƒôdzie w rankingu.",
        })

    if risk_score > 50:
        tips.append({
            "icon": "üö®",
            "title": "Co zrobiƒá gdy poda≈Çe≈õ dane?",
            "text": "Natychmiast zmie≈Ñ has≈Ça (zacznij od banku i emaila). W≈ÇƒÖcz weryfikacjƒô dwuetapowƒÖ (2FA). Zg≈Ço≈õ incydent na incydent.cert.pl.",
            "example": "Zainstaluj aplikacjƒô do 2FA (np. Google Authenticator) ‚Äî nawet je≈õli kto≈õ pozna Twoje has≈Ço, nie zaloguje siƒô bez kodu z telefonu.",
        })

    if len(tips) < 3:
        tips.append({
            "icon": "üîí",
            "title": "K≈Ç√≥dka nie oznacza bezpiecze≈Ñstwa",
            "text": "K≈Ç√≥dka w pasku adresu oznacza szyfrowane po≈ÇƒÖczenie, ale NIE gwarantuje, ≈ºe strona jest bezpieczna. Oszu≈õci te≈º u≈ºywajƒÖ HTTPS.",
            "example": "Patrz na adres obok k≈Ç√≥dki: allegro.pl jest OK, ale allegro-promocja.xyz to oszustwo ‚Äî mimo ≈ºe oba majƒÖ k≈Ç√≥dkƒô.",
        })

    return tips[:5]


def generate_verdict(risk_score: int, signals: dict, query: str) -> dict:
    """Generate AI verdict using Claude Haiku ‚Äî educational mode for non-tech users."""
    # Determine base verdict from score (new thresholds)
    if risk_score < 20:
        base_verdict = "BEZPIECZNE"
    elif risk_score <= 50:
        base_verdict = "PODEJRZANE"
    else:
        base_verdict = "OSZUSTWO"

    # Try AI-enhanced verdict
    try:
        from modules.llm_provider import ClaudeProvider
        provider = ClaudeProvider(model="claude-haiku-4-5-20251001")

        signals_summary = json.dumps(signals, ensure_ascii=False, default=str)
        if len(signals_summary) > 3000:
            signals_summary = signals_summary[:3000] + "..."

        prompt = (
            f"Jeste≈õ ekspertem od bezpiecze≈Ñstwa online. Piszesz raport dla osoby "
            f"bez wiedzy technicznej ‚Äî np. emeryta kt√≥ry szuka samochodu online.\n\n"
            f"Dane weryfikacji:\n{signals_summary}\n"
            f"Risk score: {risk_score}/100 (progi: <20 bezpieczne, 20-50 podejrzane, >50 oszustwo)\n"
            f"Sprawdzana domena: {query}\n\n"
            f"Zwr√≥ƒá WY≈ÅƒÑCZNIE JSON (bez markdown, wszystkie pola PO POLSKU):\n"
            f'{{"verdict": "{base_verdict}", '
            f'"summary": "3-4 zdania. Powiedz CO konkretnie znalaz≈Çe≈õ i DLACZEGO to niepokojƒÖce lub bezpieczne. Nie u≈ºywaj ≈ºargonu technicznego.", '
            f'"narrative": "4-6 zda≈Ñ ciep≈Çym jƒôzykiem ‚Äî co sprawdzili≈õmy, co znale≈∫li≈õmy, co to oznacza", '
            f'"red_flags": ["lista flag po polsku"], '
            f'"trust_factors": ["lista czynnik√≥w zaufania"], '
            f'"signal_explanations": [{{"signal": "nazwa", "value": "warto≈õƒá", "meaning": "co to znaczy po polsku", "risk": "green|gray|amber|red", "icon": "emoji"}}], '
            f'"problems": [{{"title": "Kr√≥tka nazwa problemu", "what_found": "Co technicznie znalaz≈Çe≈õ - 1 zdanie", "what_means": "Co to oznacza dla zwyk≈Çego cz≈Çowieka - 1-2 zdania", "real_risk": "Konkretne ryzyko np. Mo≈ºesz straciƒá pieniƒÖdze"}}], '
            f'"positives": [{{"title": "Kr√≥tka nazwa pozytywu", "what_found": "Co znalaz≈Çe≈õ - 1 zdanie", "what_means": "Dlaczego to dobry znak - 1 zdanie"}}], '
            f'"immediate_actions": ["Natychmiastowe dzia≈Çanie 1 - konkretne i wykonalne", "Dzia≈Çanie 2", "Dzia≈Çanie 3"], '
            f'"if_paid_already": ["Co zrobiƒá je≈õli ju≈º zap≈Çaci≈Çe≈õ krok 1", "Krok 2"], '
            f'"report_to": [{{"institution": "Nazwa instytucji", "url": "adres strony", "description": "Co tam zg≈Çosiƒá i po co"}}], '
            f'"educational_tips": [{{"icon": "emoji", "title": "Tytu≈Ç wskaz√≥wki", "text": "2-3 zdania edukacyjne", "example": "Konkretny przyk≈Çad jak zastosowaƒá tƒô wiedzƒô"}}], '
            f'"recommendation": "Rekomendacja 1-2 zdania"}}\n\n'
            f"WA≈ªNE:\n"
            f"- Dla OSZUSTWA: report_to musi zawieraƒá CERT Polska (incydent.cert.pl), Policjƒô, UOKiK, bank\n"
            f"- Dla PODEJRZANE: daj konkretne kroki jak zweryfikowaƒá rƒôcznie\n"
            f"- if_paid_already wype≈Çnij zawsze dla OSZUSTWO i PODEJRZANE\n"
            f"- Pisz jakby≈õ rozmawia≈Ç z osobƒÖ starszƒÖ kt√≥ra nie zna siƒô na technologii"
        )

        response_text = provider.chat(prompt, max_tokens=2500)
        clean = response_text.strip()
        if clean.startswith("```"):
            clean = clean.split("```")[1]
            if clean.startswith("json"):
                clean = clean[4:]
        try:
            result = json.loads(clean.strip())
        except json.JSONDecodeError:
            start = response_text.find("{")
            end = response_text.rfind("}") + 1
            if start >= 0 and end > start:
                result = json.loads(response_text[start:end])
            else:
                raise

        # Ensure verdict matches score-based threshold
        result["verdict"] = base_verdict
        # Ensure all fields present with fallbacks
        result.setdefault("trust_factors", _extract_trust_factors(signals))
        result.setdefault("signal_explanations", _extract_signal_explanations(signals))
        result.setdefault("narrative", _generate_narrative(risk_score, signals, query))
        result.setdefault("problems", _extract_problems(signals))
        result.setdefault("positives", _extract_positives(signals))
        result.setdefault("action", _generate_action(risk_score, query))
        result.setdefault("immediate_actions", _generate_immediate_actions(risk_score, query))
        result.setdefault("if_paid_already", _generate_if_paid_already(risk_score))
        result.setdefault("report_to", _generate_report_to(risk_score))
        result.setdefault("educational_tips", _generate_educational_tips(risk_score, signals))
        # Normalize educational_tips to dict format
        tips = result.get("educational_tips", [])
        if tips and isinstance(tips[0], str):
            result["educational_tips"] = [{"icon": "üí°", "title": "Porada", "text": t, "example": ""} for t in tips]
        return result

    except Exception as exc:
        log.warning(f"AI verdict generation failed: {exc}")
        return {
            "verdict": base_verdict,
            "summary": f"Analiza automatyczna wykaza≈Ça risk score {risk_score}/100.",
            "narrative": _generate_narrative(risk_score, signals, query),
            "red_flags": _extract_red_flags(signals),
            "trust_factors": _extract_trust_factors(signals),
            "signal_explanations": _extract_signal_explanations(signals),
            "problems": _extract_problems(signals),
            "positives": _extract_positives(signals),
            "action": _generate_action(risk_score, query),
            "immediate_actions": _generate_immediate_actions(risk_score, query),
            "if_paid_already": _generate_if_paid_already(risk_score),
            "report_to": _generate_report_to(risk_score),
            "educational_tips": _generate_educational_tips(risk_score, signals),
            "recommendation": "Zalecamy ostro≈ºno≈õƒá." if risk_score >= 20 else "Brak podejrzanych sygna≈Ç√≥w.",
        }


def _extract_red_flags(signals: dict) -> list[str]:
    """Extract human-readable red flags from signals."""
    flags = []
    whois = signals.get("whois", {})
    age = whois.get("age_days")
    if age is not None and age < 90:
        flags.append(f"WHOIS: domena zarejestrowana {age} dni temu (bardzo nowa)")
    elif age is not None and age < 365:
        flags.append(f"WHOIS: domena zarejestrowana {age} dni temu (stosunkowo nowa)")
    if whois.get("available"):
        flags.append("WHOIS: domena wyglƒÖda na niezarejestrowanƒÖ")

    gsb = signals.get("google_safe_browsing", {})
    if gsb.get("flagged"):
        flags.append(f"Google Safe Browsing: {', '.join(gsb.get('threats', []))}")

    vt = signals.get("virustotal", {})
    if vt.get("positives", 0) > 0:
        flags.append(f"VirusTotal: {vt['positives']}/{vt.get('total', 0)} silnik√≥w oznaczy≈Ço jako z≈Ço≈õliwe")

    urlhaus = signals.get("urlhaus", {})
    if urlhaus.get("blacklisted"):
        flags.append("URLhaus: domena na czarnej li≈õcie")

    gn = signals.get("greynoise", {})
    if gn.get("classification") == "malicious":
        flags.append("GreyNoise: IP oznaczone jako z≈Ço≈õliwe")

    company = signals.get("company", {})
    if company and not company.get("found", True):
        flags.append("Rejestr: firma nie znaleziona w rejestrze")

    if signals.get("disposable_email"):
        flags.append("Email: domena jednorazowego u≈ºytku (disposable)")

    mx = signals.get("mx", {})
    if mx and not mx.get("has_mx", True):
        flags.append("MX: brak rekord√≥w (domena nie obs≈Çuguje poczty)")

    wb = signals.get("wayback", {})
    if wb.get("archive_age_days") is not None and wb["archive_age_days"] < 180:
        flags.append(f"Wayback: strona w archiwum od {wb['archive_age_days']} dni")

    # New sources
    abuse = signals.get("abuseipdb", {})
    if abuse.get("abuseConfidenceScore", 0) > 20:
        flags.append(f"AbuseIPDB: wynik zaufania {abuse['abuseConfidenceScore']}% ({abuse.get('totalReports', 0)} zg≈Çosze≈Ñ)")

    otx = signals.get("otx", {})
    if otx.get("pulse_count", 0) > 0:
        flags.append(f"OTX: {otx['pulse_count']} puls√≥w threat intelligence")

    ipinfo = signals.get("ipinfo", {})
    if (ipinfo.get("country") or "").upper() in ("UA", "RU", "KP", "IR", "CN"):
        flags.append(f"IPinfo: hosting w kraju podwy≈ºszonego ryzyka ({ipinfo['country']})")

    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc and not spf_dmarc.get("has_spf") and not spf_dmarc.get("has_dmarc"):
        flags.append("DNS: brak SPF i DMARC (brak ochrony przed spoofingiem)")

    crtsh = signals.get("crtsh", {})
    if crtsh.get("cert_age_days") is not None and crtsh["cert_age_days"] < 30:
        flags.append(f"crt.sh: certyfikat SSL wystawiony {crtsh['cert_age_days']} dni temu")

    return flags


def _extract_trust_factors(signals: dict) -> list[str]:
    """Extract trust-positive factors from signals."""
    factors = []

    tranco = signals.get("tranco", {})
    rank = tranco.get("rank")
    if rank is not None:
        if rank <= 10000:
            factors.append(f"Tranco: domena w top 10K najpopularniejszych stron (pozycja {rank})")
        elif rank <= 100000:
            factors.append(f"Tranco: domena w top 100K popularnych stron (pozycja {rank})")
        elif rank <= 1000000:
            factors.append(f"Tranco: domena w top 1M stron (pozycja {rank})")

    whois = signals.get("whois", {})
    age = whois.get("age_days")
    if age is not None:
        if age > 3650:
            factors.append(f"WHOIS: domena zarejestrowana od {age // 365} lat (stabilna)")
        elif age > 1825:
            factors.append(f"WHOIS: domena zarejestrowana od {age // 365} lat")

    abuse = signals.get("abuseipdb", {})
    if abuse.get("isWhitelisted"):
        factors.append("AbuseIPDB: IP na bia≈Çej li≈õcie (zaufane)")

    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc.get("has_spf") and spf_dmarc.get("has_dmarc"):
        factors.append("DNS: SPF + DMARC skonfigurowane (ochrona przed spoofingiem)")

    company = signals.get("company", {})
    if company and company.get("found"):
        registry = company.get("registry", "rejestr")
        factors.append(f"Rejestr: firma potwierdzona w {registry}")

    crtsh = signals.get("crtsh", {})
    cert_age = crtsh.get("cert_age_days")
    if cert_age is not None and cert_age > 730:
        factors.append(f"crt.sh: certyfikat SSL od {cert_age // 365} lat (d≈Çugotrwa≈Çy)")

    otx = signals.get("otx", {})
    if otx.get("validation") and len(otx["validation"]) > 0:
        factors.append("OTX: domena poddana walidacji threat intelligence")

    return factors


def _extract_signal_explanations(signals: dict) -> list[dict]:
    """Generate per-signal explanations for educational purposes."""
    explanations = []

    def _add(signal: str, value: str, meaning: str, risk: str, icon: str):
        explanations.append({"signal": signal, "value": value, "meaning": meaning, "risk": risk, "icon": icon})

    # WHOIS
    whois = signals.get("whois", {})
    age = whois.get("age_days")
    if age is not None:
        if age < 90:
            _add("WHOIS wiek", f"{age} dni", "Bardzo nowa domena ‚Äî oszu≈õci czƒôsto rejestrujƒÖ domeny tu≈º przed atakiem", "red", "üî¥")
        elif age < 365:
            _add("WHOIS wiek", f"{age} dni", "Stosunkowo nowa domena ‚Äî warto zachowaƒá czujno≈õƒá", "amber", "üü°")
        elif age > 3650:
            _add("WHOIS wiek", f"{age // 365} lat", "D≈Çugo dzia≈ÇajƒÖca domena ‚Äî to dobry znak zaufania", "green", "üü¢")
        else:
            _add("WHOIS wiek", f"{age} dni", "Domena o umiarkowanym sta≈ºu", "gray", "‚ö™")

    # GSB
    gsb = signals.get("google_safe_browsing", {})
    if gsb.get("available"):
        if gsb.get("flagged"):
            _add("Google Safe Browsing", "OZNACZONE", "Google aktywnie ostrzega przed tƒÖ stronƒÖ", "red", "üî¥")
        else:
            _add("Google Safe Browsing", "Czyste", "Google nie znalaz≈Ç zagro≈ºe≈Ñ na tej stronie", "green", "üü¢")

    # VT
    vt = signals.get("virustotal", {})
    if vt.get("available"):
        pos = vt.get("positives", 0)
        total = vt.get("total", 0)
        if pos >= 5:
            _add("VirusTotal", f"{pos}/{total}", "Wiele silnik√≥w antywirusowych oznaczy≈Ço ten URL jako niebezpieczny", "red", "üî¥")
        elif pos >= 2:
            _add("VirusTotal", f"{pos}/{total}", "Kilka silnik√≥w antywirusowych ma zastrze≈ºenia", "amber", "üü°")
        elif pos > 0:
            _add("VirusTotal", f"{pos}/{total}", "Pojedyncze oznaczenie ‚Äî mo≈ºe byƒá fa≈Çszywy alarm", "gray", "‚ö™")
        else:
            _add("VirusTotal", f"0/{total}", "≈ªaden silnik antywirusowy nie znalaz≈Ç zagro≈ºe≈Ñ", "green", "üü¢")

    # Tranco
    tranco = signals.get("tranco", {})
    rank = tranco.get("rank")
    if tranco.get("available"):
        if rank is not None:
            _add("Tranco Ranking", f"#{rank}", f"Domena jest w top {rank} najpopularniejszych stron ‚Äî to wskazuje na legitymalno≈õƒá", "green", "üü¢")
        else:
            _add("Tranco Ranking", "Brak w rankingu", "Domena nie jest w top 1M popularnych stron", "gray", "‚ö™")

    # AbuseIPDB
    abuse = signals.get("abuseipdb", {})
    if abuse.get("available"):
        ascore = abuse.get("abuseConfidenceScore", 0)
        if ascore > 50:
            _add("AbuseIPDB", f"{ascore}%", "Wysokie prawdopodobie≈Ñstwo nadu≈ºyƒá z tego IP", "red", "üî¥")
        elif ascore > 20:
            _add("AbuseIPDB", f"{ascore}%", "Umiarkowana liczba zg≈Çosze≈Ñ nadu≈ºyƒá z tego IP", "amber", "üü°")
        elif abuse.get("isWhitelisted"):
            _add("AbuseIPDB", "Whitelisted", "IP jest na bia≈Çej li≈õcie ‚Äî zaufane ≈∫r√≥d≈Ço", "green", "üü¢")
        else:
            _add("AbuseIPDB", f"{ascore}%", "Brak znaczƒÖcych zg≈Çosze≈Ñ nadu≈ºyƒá", "green", "üü¢")

    # OTX
    otx = signals.get("otx", {})
    if otx.get("available"):
        pulses = otx.get("pulse_count", 0)
        if pulses > 5:
            _add("OTX AlienVault", f"{pulses} puls√≥w", "Domena pojawia siƒô w wielu raportach o zagro≈ºeniach", "red", "üî¥")
        elif pulses > 0:
            _add("OTX AlienVault", f"{pulses} puls√≥w", "Domena pojawi≈Ça siƒô w raportach threat intelligence", "amber", "üü°")
        else:
            _add("OTX AlienVault", "0 puls√≥w", "Brak raport√≥w o zagro≈ºeniach zwiƒÖzanych z tƒÖ domenƒÖ", "green", "üü¢")

    # SPF/DMARC
    spf_dmarc = signals.get("spf_dmarc", {})
    if spf_dmarc:
        has_spf = spf_dmarc.get("has_spf", False)
        has_dmarc = spf_dmarc.get("has_dmarc", False)
        if has_spf and has_dmarc:
            _add("SPF + DMARC", "Oba skonfigurowane", "Domena chroni przed podszywaniem siƒô (spoofingiem)", "green", "üü¢")
        elif has_spf or has_dmarc:
            parts = []
            if has_spf:
                parts.append("SPF")
            if has_dmarc:
                parts.append("DMARC")
            _add("SPF/DMARC", " + ".join(parts), "Czƒô≈õciowa ochrona przed spoofingiem", "gray", "‚ö™")
        else:
            _add("SPF/DMARC", "Brak", "Domena nie chroni przed podszywaniem siƒô pod nadawcƒô", "amber", "üü°")

    # crt.sh
    crtsh = signals.get("crtsh", {})
    cert_age = crtsh.get("cert_age_days")
    if cert_age is not None:
        if cert_age < 30:
            _add("Certyfikat SSL", f"{cert_age} dni", "Bardzo nowy certyfikat ‚Äî oszu≈õci czƒôsto uzyskujƒÖ SSL tu≈º przed atakiem", "red", "üî¥")
        elif cert_age > 730:
            _add("Certyfikat SSL", f"{cert_age // 365} lat", "D≈Çugotrwa≈Çy certyfikat ‚Äî dobry znak", "green", "üü¢")
        else:
            _add("Certyfikat SSL", f"{cert_age} dni", "Certyfikat o standardowym wieku", "gray", "‚ö™")

    # IPinfo
    ipinfo = signals.get("ipinfo", {})
    if ipinfo.get("available"):
        country = (ipinfo.get("country") or "").upper()
        if country in ("UA", "RU", "KP", "IR", "CN"):
            _add("IPinfo", f"{ipinfo.get('org', '')} ({country})", "Hosting w kraju podwy≈ºszonego ryzyka cybernetycznego", "amber", "üü°")
        else:
            _add("IPinfo", f"{ipinfo.get('org', '')} ({country})", "Lokalizacja serwera", "gray", "‚ö™")

    return explanations


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  MAIN VERIFY METHODS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class CyrberVerify:
    """Main verification engine."""

    def verify_url(self, url: str) -> dict:
        """Verify a URL for fraud signals."""
        if not url.startswith("http"):
            url = "https://" + url

        domain = _extract_domain(url)
        ip = _resolve_domain_ip(domain)

        signals = {}

        # WHOIS
        signals["whois"] = _whois_lookup(domain)

        # Google Safe Browsing
        signals["google_safe_browsing"] = _google_safe_browsing(url)

        # VirusTotal
        signals["virustotal"] = _virustotal_url(url)

        # URLhaus (reuse existing module)
        signals["urlhaus"] = _urlhaus_lookup(domain)

        # GreyNoise (IP only)
        if ip:
            signals["greynoise"] = _greynoise_lookup(ip)
            signals["resolved_ip"] = ip

        # Wayback Machine
        signals["wayback"] = _wayback_first(domain)

        # ‚îÄ‚îÄ New v2 sources ‚îÄ‚îÄ
        signals["rdap"] = _rdap_lookup(domain)
        signals["crtsh"] = _crtsh_lookup(domain)
        signals["spf_dmarc"] = _check_spf_dmarc(domain)
        signals["tranco"] = _tranco_lookup(domain)
        if ip:
            signals["ipinfo"] = _ipinfo_lookup(ip)
            signals["abuseipdb"] = _abuseipdb_lookup(ip)
        signals["otx"] = _otx_lookup(domain)

        risk_score = calculate_risk(signals)
        verdict = generate_verdict(risk_score, signals, url)

        return {
            "query": url,
            "type": "url",
            "domain": domain,
            "risk_score": risk_score,
            "signals": signals,
            **verdict,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }

    def verify_company(self, query: str, country: str = "PL") -> dict:
        """Verify a company in public registries."""
        signals = {}
        country = country.upper()

        if country == "PL":
            krs = _krs_lookup(query)
            ceidg = _ceidg_lookup(query)
            # Use whichever found results
            if krs.get("found"):
                signals["company"] = krs
            elif ceidg.get("found"):
                signals["company"] = ceidg
            else:
                signals["company"] = {"found": False, "registry": "KRS+CEIDG", "krs": krs, "ceidg": ceidg}
        elif country == "UK":
            signals["company"] = _companies_house_lookup(query)
        else:
            signals["company"] = {"found": False, "registry": "unsupported_country"}

        # If company has a website, check the domain too
        company = signals.get("company", {})
        company_name = company.get("name", query)

        risk_score = calculate_risk(signals)
        verdict = generate_verdict(risk_score, signals, query)

        return {
            "query": query,
            "type": "company",
            "country": country,
            "risk_score": risk_score,
            "signals": signals,
            **verdict,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }

    def verify_email(self, email: str) -> dict:
        """Verify an email address for fraud signals."""
        signals = {}

        # Extract domain
        parts = email.split("@")
        if len(parts) != 2:
            return {
                "query": email, "type": "email", "risk_score": 80,
                "verdict": "OSZUSTWO", "summary": "Nieprawid≈Çowy format adresu email.",
                "narrative": "Podany adres email ma nieprawid≈Çowy format ‚Äî brakuje znaku @ lub domeny. Prawid≈Çowy email wyglƒÖda tak: nazwa@domena.pl. Nie mogli≈õmy przeprowadziƒá dalszej analizy.",
                "red_flags": ["Nieprawid≈Çowy format email"],
                "trust_factors": [], "signal_explanations": [],
                "problems": [{"title": "Nieprawid≈Çowy format", "what_found": "Adres email nie zawiera znaku @ z domenƒÖ.", "what_means": "To nie jest prawdziwy adres email.", "real_risk": "Nie mo≈ºna zweryfikowaƒá nadawcy."}],
                "positives": [],
                "action": "Sprawd≈∫ poprawno≈õƒá adresu email i spr√≥buj ponownie.",
                "immediate_actions": ["Sprawd≈∫ poprawno≈õƒá adresu email i spr√≥buj ponownie"],
                "if_paid_already": [],
                "report_to": [],
                "educational_tips": [{"icon": "üìß", "title": "Format email", "text": "Prawid≈Çowy adres email zawsze ma format: nazwa@domena.pl", "example": "jan.kowalski@gmail.com ‚Äî to poprawny adres."}],
                "recommendation": "Podaj poprawny adres email.",
                "signals": {}, "timestamp": datetime.now(timezone.utc).isoformat(),
            }

        domain = parts[1].lower()

        # Disposable email check
        disposable_domains = _load_disposable_domains()
        signals["disposable_email"] = domain in disposable_domains

        # MX records
        signals["mx"] = _check_mx(domain)

        # Domain WHOIS
        signals["whois"] = _whois_lookup(domain)

        # URLhaus for domain
        signals["urlhaus"] = _urlhaus_lookup(domain)

        # SPF/DMARC for email domain
        signals["spf_dmarc"] = _check_spf_dmarc(domain)

        risk_score = calculate_risk(signals)
        verdict = generate_verdict(risk_score, signals, email)

        return {
            "query": email,
            "type": "email",
            "domain": domain,
            "risk_score": risk_score,
            "signals": signals,
            **verdict,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }


def detect_query_type(query: str) -> str:
    """Auto-detect query type: url, email, or company."""
    q = query.strip()
    if "@" in q:
        return "email"
    if q.startswith("http://") or q.startswith("https://"):
        return "url"
    if "." in q and not " " in q:
        return "url"
    return "company"
